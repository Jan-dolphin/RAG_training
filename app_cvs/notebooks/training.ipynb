{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV RAG Training Notebook\n",
    "\n",
    "Tento notebook umo≈æ≈àuje ruƒçn√≠ spou≈°tƒõn√≠ a testov√°n√≠ tr√©novac√≠ho procesu RAG syst√©mu pro vyhled√°v√°n√≠ v ≈æivotopisech.\n",
    "\n",
    "## Co se dƒõje bƒõhem tr√©nov√°n√≠:\n",
    "\n",
    "1. **Naƒçten√≠ CV** - Naƒçtou se v≈°echny DOCX soubory z datov√©ho adres√°≈ôe\n",
    "2. **Setup embeddings** - P≈ôiprav√≠ se Azure OpenAI embeddings\n",
    "3. **Setup vector store** - Vytvo≈ô√≠ se pr√°zdn√Ω ChromaDB vectorstore\n",
    "4. **Inicializace retrieveru** - ParentDocumentRetriever:\n",
    "   - Rozdƒõl√≠ ka≈æd√© CV na parent chunks (~2000 znak≈Ø)\n",
    "   - Rozdƒõl√≠ parent chunks na child chunks (~400 znak≈Ø)\n",
    "   - Child chunks se indexuj√≠ do vectorstore (pro vyhled√°v√°n√≠)\n",
    "   - Parent chunks se ukl√°daj√≠ do docstore (pro context)\n",
    "5. **Test retrieval** - Vyzkou≈°√≠ nƒõkolik testovac√≠ch dotaz≈Ø"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import knihoven a konfigurace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Knihovny naƒçteny\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# P≈ôidat parent directory do sys.path pro importy\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Nastaven√≠ logging pro viditelnost procesu\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Import aplikaƒçn√≠ch modul≈Ø\n",
    "from src.config import AppConfig\n",
    "from src.document_loader import CVDocumentLoader\n",
    "from src.embeddings import EmbeddingsManager\n",
    "from src.vector_store import VectorStoreManager\n",
    "from src.parent_retriever import CVParentRetriever\n",
    "\n",
    "print(\"‚úì Knihovny naƒçteny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naƒçten√≠ konfigurace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Konfigurace:\n",
      "  Data directory: ./data/OneDrive_2025-12-16\n",
      "  Vector store: ./chroma_db\n",
      "  Parent chunk size: 2000\n",
      "  Child chunk size: 400\n",
      "  Batch size: 5\n",
      "  Batch delay: 2.0s\n"
     ]
    }
   ],
   "source": [
    "# Naƒçten√≠ konfigurace z .env souboru\n",
    "config = AppConfig()\n",
    "\n",
    "print(\"\\nüìã Konfigurace:\")\n",
    "print(f\"  Data directory: {config.rag.data_directory}\")\n",
    "print(f\"  Vector store: {config.rag.persist_directory}\")\n",
    "print(f\"  Parent chunk size: {config.rag.parent_chunk_size}\")\n",
    "print(f\"  Child chunk size: {config.rag.child_chunk_size}\")\n",
    "print(f\"  Batch size: {config.azure.batch_size}\")\n",
    "print(f\"  Batch delay: {config.azure.batch_delay}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KROK 1: Naƒçten√≠ CV dokument≈Ø\n",
    "\n",
    "Naƒçte v≈°echny `.docx` soubory z datov√©ho adres√°≈ôe a p≈ôevede je na `Candidate` objekty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:40:32,709 - src.document_loader - INFO - Found 27 DOCX files in ..\\data\\OneDrive_2025-12-16\n",
      "2025-12-17 16:40:32,736 - src.document_loader - INFO - Loaded CV for Bal√°ƒçek Daniel (3020 characters)\n",
      "2025-12-17 16:40:32,760 - src.document_loader - INFO - Loaded CV for Bob≈Ørka Vojtƒõch (2458 characters)\n",
      "2025-12-17 16:40:32,791 - src.document_loader - INFO - Loaded CV for Bronec Ond≈ôej (3757 characters)\n",
      "2025-12-17 16:40:32,815 - src.document_loader - INFO - Loaded CV for Bukovsk√Ω Petr (2628 characters)\n",
      "2025-12-17 16:40:32,830 - src.document_loader - INFO - Loaded CV for B√≠mov√° Kamila (2042 characters)\n",
      "2025-12-17 16:40:32,850 - src.document_loader - INFO - Loaded CV for Dlugo≈°ov√° Lenka (2383 characters)\n",
      "2025-12-17 16:40:32,868 - src.document_loader - INFO - Loaded CV for Duleba Peter (2873 characters)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KROK 1: Naƒç√≠t√°n√≠ CV dokument≈Ø\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:40:32,883 - src.document_loader - INFO - Loaded CV for Fejfarov√° Julia (1445 characters)\n",
      "2025-12-17 16:40:32,896 - src.document_loader - INFO - Loaded CV for Fejfar Ond≈ôej (1289 characters)\n",
      "2025-12-17 16:40:32,919 - src.document_loader - INFO - Loaded CV for Gleb Tcypin (2543 characters)\n",
      "2025-12-17 16:40:32,949 - src.document_loader - INFO - Loaded CV for Hlavat√° Michaela (5445 characters)\n",
      "2025-12-17 16:40:32,959 - src.document_loader - INFO - Loaded CV for Hlinkov√° Zuzana (2615 characters)\n",
      "2025-12-17 16:40:32,983 - src.document_loader - INFO - Loaded CV for Holman Martin (1559 characters)\n",
      "2025-12-17 16:40:33,013 - src.document_loader - INFO - Loaded CV for Hrd√Ω Daniel (2399 characters)\n",
      "2025-12-17 16:40:33,048 - src.document_loader - INFO - Loaded CV for Hu≈àa Tom√°≈° (3930 characters)\n",
      "2025-12-17 16:40:33,067 - src.document_loader - INFO - Loaded CV for Hu≈°ek Michal (2354 characters)\n",
      "2025-12-17 16:40:33,089 - src.document_loader - INFO - Loaded CV for Karlovsk√Ω Luk√°≈° (3653 characters)\n",
      "2025-12-17 16:40:33,128 - src.document_loader - INFO - Loaded CV for Kol√°≈ô Petr (8774 characters)\n",
      "2025-12-17 16:40:33,148 - src.document_loader - INFO - Loaded CV for Konvalinka Michal (2949 characters)\n",
      "2025-12-17 16:40:33,176 - src.document_loader - INFO - Loaded CV for Kub√°k Adam (3349 characters)\n",
      "2025-12-17 16:40:33,217 - src.document_loader - INFO - Loaded CV for Kulbakov Nikolaj (5157 characters)\n",
      "2025-12-17 16:40:33,242 - src.document_loader - INFO - Loaded CV for Kuƒçerov√° Lucie (1193 characters)\n",
      "2025-12-17 16:40:33,270 - src.document_loader - INFO - Loaded CV for Leci√°n Michal (2430 characters)\n",
      "2025-12-17 16:40:33,289 - src.document_loader - INFO - Loaded CV for L√°tal Michael (1938 characters)\n",
      "2025-12-17 16:40:33,321 - src.document_loader - INFO - Loaded CV for Maru≈°√°k Jan (2021 characters)\n",
      "2025-12-17 16:40:33,417 - src.document_loader - INFO - Loaded CV for Nƒõmeƒçek Tom√°≈° (9249 characters)\n",
      "2025-12-17 16:40:33,451 - src.document_loader - INFO - Loaded CV for Petr Jan (4940 characters)\n",
      "2025-12-17 16:40:33,453 - src.document_loader - INFO - Successfully loaded 27 CVs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Naƒçteno 27 CV\n",
      "\n",
      "Prvn√≠ch 5 kandid√°t≈Ø:\n",
      "  1. Bal√°ƒçek Daniel (3020 znak≈Ø)\n",
      "  2. Bob≈Ørka Vojtƒõch (2458 znak≈Ø)\n",
      "  3. Bronec Ond≈ôej (3757 znak≈Ø)\n",
      "  4. Bukovsk√Ω Petr (2628 znak≈Ø)\n",
      "  5. B√≠mov√° Kamila (2042 znak≈Ø)\n",
      "  ... a dal≈°√≠ch 22\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KROK 1: Naƒç√≠t√°n√≠ CV dokument≈Ø\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Vytvo≈ôen√≠ loaderu\n",
    "loader = CVDocumentLoader(config.rag.data_directory_ntb)\n",
    "\n",
    "# Naƒçten√≠ v≈°ech CV\n",
    "candidates = loader.load_all_cvs()\n",
    "\n",
    "print(f\"\\n‚úì Naƒçteno {len(candidates)} CV\")\n",
    "print(\"\\nPrvn√≠ch 5 kandid√°t≈Ø:\")\n",
    "for i, candidate in enumerate(candidates[:5], 1):\n",
    "    print(f\"  {i}. {candidate.name} ({len(candidate.full_cv_text)} znak≈Ø)\")\n",
    "\n",
    "if len(candidates) > 5:\n",
    "    print(f\"  ... a dal≈°√≠ch {len(candidates) - 5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pod√≠vejte se na jedno CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ P≈ô√≠klad CV: Bal√°ƒçek Daniel\n",
      "D√©lka: 3020 znak≈Ø\n",
      "\n",
      "Prvn√≠ch 500 znak≈Ø:\n",
      "--------------------------------------------------------------------------------\n",
      "www.dolphinconsulting.cz\t\n",
      "\n",
      "Daniel Bal√°ƒçek\n",
      "\n",
      "BI consultant \n",
      "\n",
      " Praha\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Dashboard and report development and design\n",
      "\n",
      "User requirements analysis and documentation\n",
      "\n",
      "Business and data analysis\n",
      "\n",
      "\n",
      "\n",
      "Skills & knowledge\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "General Skills\n",
      "\n",
      "Dashboard and report development and design \n",
      "\n",
      "Datawarehouse architecture principles and principles of BI\n",
      "\n",
      "Data modeling\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "Applications\n",
      "\n",
      "MS Excel - advanced\n",
      "\n",
      "Qlik Sense ‚Äì advanced \n",
      "\n",
      "Qlik NPrinting ‚Äì advanced\n",
      "\n",
      "Q\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Zobrazen√≠ prvn√≠ch 500 znak≈Ø z prvn√≠ho CV\n",
    "if candidates:\n",
    "    first_candidate = candidates[0]\n",
    "    print(f\"\\nüìÑ P≈ô√≠klad CV: {first_candidate.name}\")\n",
    "    print(f\"D√©lka: {len(first_candidate.full_cv_text)} znak≈Ø\")\n",
    "    print(f\"\\nPrvn√≠ch 500 znak≈Ø:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(first_candidate.full_cv_text[:500])\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P≈ôevod na LangChain Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:40:33,501 - src.document_loader - INFO - Converted 27 candidates to LangChain documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Vytvo≈ôeno 27 LangChain Documents\n",
      "\n",
      "P≈ô√≠klad metadat prvn√≠ho dokumentu:\n",
      "{'candidate_name': 'Bal√°ƒçek Daniel', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bal√°ƒçek_Daniel_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bal√°ƒçek_Daniel_CV_EN.docx', 'file_size': 496940, 'text_length': 3020}\n"
     ]
    }
   ],
   "source": [
    "# P≈ôevod kandid√°t≈Ø na LangChain Documents\n",
    "documents = loader.convert_to_langchain_documents(candidates)\n",
    "\n",
    "print(f\"\\n‚úì Vytvo≈ôeno {len(documents)} LangChain Documents\")\n",
    "print(\"\\nP≈ô√≠klad metadat prvn√≠ho dokumentu:\")\n",
    "if documents:\n",
    "    print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KROK 2: Setup Azure OpenAI Embeddings\n",
    "\n",
    "P≈ôiprav√≠ embeddings model pro vytv√°≈ôen√≠ vektorov√Ωch reprezentac√≠ textu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KROK 2: Setup Embeddings\n",
      "================================================================================\n",
      "\n",
      "‚úì Embeddings manager vytvo≈ôen\n",
      "  Model: text-embedding-ada-002-dolphin-1\n",
      "  Endpoint: https://oai-dolphin-1.openai.azure.com\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KROK 2: Setup Embeddings\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "embeddings_mgr = EmbeddingsManager(config.azure)\n",
    "\n",
    "print(f\"\\n‚úì Embeddings manager vytvo≈ôen\")\n",
    "print(f\"  Model: {config.azure.embedding_deployment}\")\n",
    "print(f\"  Endpoint: {config.azure.endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test p≈ôipojen√≠ k Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:40:33,553 - src.embeddings - INFO - Initializing Azure OpenAI Embeddings with deployment: text-embedding-ada-002-dolphin-1\n",
      "2025-12-17 16:40:37,515 - src.embeddings - INFO - Embeddings initialized successfully\n",
      "2025-12-17 16:40:45,654 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:40:45,670 - src.embeddings - INFO - Embeddings connection test successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì P≈ôipojen√≠ k Azure OpenAI √∫spƒõ≈°n√©\n"
     ]
    }
   ],
   "source": [
    "# Test p≈ôipojen√≠\n",
    "if embeddings_mgr.test_connection():\n",
    "    print(\"\\n‚úì P≈ôipojen√≠ k Azure OpenAI √∫spƒõ≈°n√©\")\n",
    "else:\n",
    "    print(\"\\n‚úó P≈ôipojen√≠ k Azure OpenAI selhalo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KROK 3: Setup Vector Store\n",
    "\n",
    "Vytvo≈ô√≠ pr√°zdn√Ω ChromaDB vectorstore (nebo naƒçte existuj√≠c√≠)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:40:45,707 - src.vector_store - INFO - Clearing vector store at chroma_db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KROK 3: Setup Vector Store\n",
      "================================================================================\n",
      "\n",
      "Ma≈æu existuj√≠c√≠ vectorstore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:40:45,898 - src.vector_store - INFO - Vector store cleared\n",
      "2025-12-17 16:40:45,901 - src.vector_store - INFO - Creating new empty vector store at chroma_db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vytv√°≈ô√≠m pr√°zdn√Ω vectorstore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jan.petr\\OneDrive - dolphinconsulting.cz\\Projects\\rag-training\\app_cvs\\src\\vector_store.py:66: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  self._vectorstore = Chroma(\n",
      "2025-12-17 16:40:54,215 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-12-17 16:40:55,415 - src.vector_store - INFO - Empty vector store created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Vector store p≈ôipraven\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KROK 3: Setup Vector Store\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "vs_manager = VectorStoreManager(\n",
    "    config.rag,\n",
    "    embeddings_mgr.get_embeddings()\n",
    ")\n",
    "\n",
    "# Smaz√°n√≠ existuj√≠c√≠ho vectorstore (pro ƒçist√© tr√©nov√°n√≠)\n",
    "print(\"\\nMa≈æu existuj√≠c√≠ vectorstore...\")\n",
    "vs_manager.clear_vectorstore()\n",
    "\n",
    "# Vytvo≈ôen√≠ pr√°zdn√©ho vectorstore\n",
    "print(\"Vytv√°≈ô√≠m pr√°zdn√Ω vectorstore...\")\n",
    "vectorstore = vs_manager.create_or_load_vectorstore()\n",
    "\n",
    "print(\"\\n‚úì Vector store p≈ôipraven\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KROK 4: Inicializace Parent Document Retrieveru\n",
    "\n",
    "**Toto je kl√≠ƒçov√Ω krok!**\n",
    "\n",
    "ParentDocumentRetriever:\n",
    "1. Rozdƒõl√≠ ka≈æd√© CV na **parent chunks** (velk√© kusy ~2000 znak≈Ø)\n",
    "2. Rozdƒõl√≠ ka≈æd√Ω parent chunk na **child chunks** (mal√© kusy ~400 znak≈Ø)\n",
    "3. **Child chunks** se indexuj√≠ do vectorstore (pou≈æ√≠vaj√≠ se pro vyhled√°v√°n√≠)\n",
    "4. **Parent chunks** se ukl√°daj√≠ do docstore (vracej√≠ se jako kontext)\n",
    "5. Pamatuje si mapov√°n√≠: kter√Ω child chunk pat≈ô√≠ ke kter√©mu parent chunku\n",
    "\n",
    "**Batch processing:**\n",
    "- Poƒç√≠t√° skuteƒçn√Ω poƒçet child chunks (ne jen poƒçet CV)\n",
    "- Po ka≈æd√Ωch ~50 chunc√≠ch udƒõl√° pauzu (rate limit protection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:40:55,448 - src.parent_retriever - INFO - Initializing Parent Retriever - Parent chunks: 2000, Child chunks: 400\n",
      "2025-12-17 16:40:55,450 - src.parent_retriever - INFO - Docstore path: chroma_db\\docstore\n",
      "2025-12-17 16:40:55,453 - src.parent_retriever - INFO - Initializing retriever with 27 CV documents\n",
      "2025-12-17 16:40:55,456 - src.parent_retriever - INFO - Using batch processing for retriever initialization: batch_size=5\n",
      "2025-12-17 16:40:55,457 - src.parent_retriever - INFO - Pre-splitting 27 documents into child chunks...\n",
      "2025-12-17 16:40:55,471 - src.parent_retriever - INFO - Total child chunks: 273\n",
      "2025-12-17 16:40:55,472 - src.parent_retriever - INFO - Processing in 55 batches of ~5 chunks each\n",
      "2025-12-17 16:40:55,472 - src.parent_retriever - INFO - Document 'Bal√°ƒçek Daniel': 10 child chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KROK 4: Inicializace Parent Document Retriever\n",
      "================================================================================\n",
      "\n",
      "Zpracov√°v√°m 27 dokument≈Ø...\n",
      "Batch size: 5 chunks\n",
      "Batch delay: 2.0s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:41:03,420 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:03,946 - src.parent_retriever - INFO - Processed 10/273 chunks (1 batches)\n",
      "2025-12-17 16:41:03,948 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:05,951 - src.parent_retriever - INFO - Document 'Bob≈Ørka Vojtƒõch': 7 child chunks\n",
      "2025-12-17 16:41:06,049 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:06,152 - src.parent_retriever - INFO - Processed 17/273 chunks (2 batches)\n",
      "2025-12-17 16:41:06,154 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:08,158 - src.parent_retriever - INFO - Document 'Bronec Ond≈ôej': 11 child chunks\n",
      "2025-12-17 16:41:08,288 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:08,474 - src.parent_retriever - INFO - Processed 28/273 chunks (3 batches)\n",
      "2025-12-17 16:41:08,479 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:10,483 - src.parent_retriever - INFO - Document 'Bukovsk√Ω Petr': 8 child chunks\n",
      "2025-12-17 16:41:10,631 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:10,796 - src.parent_retriever - INFO - Processed 36/273 chunks (4 batches)\n",
      "2025-12-17 16:41:10,799 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:12,802 - src.parent_retriever - INFO - Document 'B√≠mov√° Kamila': 6 child chunks\n",
      "2025-12-17 16:41:12,903 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:13,003 - src.parent_retriever - INFO - Processed 42/273 chunks (5 batches)\n",
      "2025-12-17 16:41:13,005 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:15,009 - src.parent_retriever - INFO - Document 'Dlugo≈°ov√° Lenka': 7 child chunks\n",
      "2025-12-17 16:41:15,132 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:15,237 - src.parent_retriever - INFO - Processed 49/273 chunks (6 batches)\n",
      "2025-12-17 16:41:15,240 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:17,244 - src.parent_retriever - INFO - Document 'Duleba Peter': 10 child chunks\n",
      "2025-12-17 16:41:17,422 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:17,541 - src.parent_retriever - INFO - Processed 59/273 chunks (7 batches)\n",
      "2025-12-17 16:41:17,543 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:19,545 - src.parent_retriever - INFO - Document 'Fejfarov√° Julia': 5 child chunks\n",
      "2025-12-17 16:41:19,617 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:19,686 - src.parent_retriever - INFO - Processed 64/273 chunks (8 batches)\n",
      "2025-12-17 16:41:19,688 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:21,693 - src.parent_retriever - INFO - Document 'Fejfar Ond≈ôej': 5 child chunks\n",
      "2025-12-17 16:41:21,858 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:21,963 - src.parent_retriever - INFO - Processed 69/273 chunks (9 batches)\n",
      "2025-12-17 16:41:21,968 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:23,986 - src.parent_retriever - INFO - Document 'Gleb Tcypin': 8 child chunks\n",
      "2025-12-17 16:41:24,575 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:24,728 - src.parent_retriever - INFO - Processed 77/273 chunks (10 batches)\n",
      "2025-12-17 16:41:24,732 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:26,737 - src.parent_retriever - INFO - Document 'Hlavat√° Michaela': 17 child chunks\n",
      "2025-12-17 16:41:26,867 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:27,062 - src.parent_retriever - INFO - Processed 94/273 chunks (11 batches)\n",
      "2025-12-17 16:41:27,064 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:29,066 - src.parent_retriever - INFO - Document 'Hlinkov√° Zuzana': 8 child chunks\n",
      "2025-12-17 16:41:29,202 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:29,333 - src.parent_retriever - INFO - Processed 102/273 chunks (12 batches)\n",
      "2025-12-17 16:41:29,336 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:31,339 - src.parent_retriever - INFO - Document 'Holman Martin': 5 child chunks\n",
      "2025-12-17 16:41:31,543 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:31,627 - src.parent_retriever - INFO - Processed 107/273 chunks (13 batches)\n",
      "2025-12-17 16:41:31,629 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:33,632 - src.parent_retriever - INFO - Document 'Hrd√Ω Daniel': 7 child chunks\n",
      "2025-12-17 16:41:33,774 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:33,864 - src.parent_retriever - INFO - Processed 114/273 chunks (14 batches)\n",
      "2025-12-17 16:41:33,866 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:35,870 - src.parent_retriever - INFO - Document 'Hu≈àa Tom√°≈°': 12 child chunks\n",
      "2025-12-17 16:41:36,039 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:36,199 - src.parent_retriever - INFO - Processed 126/273 chunks (15 batches)\n",
      "2025-12-17 16:41:36,201 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:38,204 - src.parent_retriever - INFO - Document 'Hu≈°ek Michal': 7 child chunks\n",
      "2025-12-17 16:41:38,291 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:38,416 - src.parent_retriever - INFO - Processed 133/273 chunks (16 batches)\n",
      "2025-12-17 16:41:38,417 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:40,420 - src.parent_retriever - INFO - Document 'Karlovsk√Ω Luk√°≈°': 11 child chunks\n",
      "2025-12-17 16:41:40,564 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:41:40,767 - src.parent_retriever - INFO - Processed 144/273 chunks (17 batches)\n",
      "2025-12-17 16:41:40,772 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:41:42,779 - src.parent_retriever - INFO - Document 'Kol√°≈ô Petr': 28 child chunks\n",
      "2025-12-17 16:41:43,056 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-12-17 16:41:43,060 - openai._base_client - INFO - Retrying request to /embeddings in 26.000000 seconds\n",
      "2025-12-17 16:42:16,910 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:17,425 - src.parent_retriever - INFO - Processed 172/273 chunks (18 batches)\n",
      "2025-12-17 16:42:17,429 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:42:19,435 - src.parent_retriever - INFO - Document 'Konvalinka Michal': 9 child chunks\n",
      "2025-12-17 16:42:19,546 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:19,764 - src.parent_retriever - INFO - Processed 181/273 chunks (19 batches)\n",
      "2025-12-17 16:42:19,769 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:42:21,774 - src.parent_retriever - INFO - Document 'Kub√°k Adam': 10 child chunks\n",
      "2025-12-17 16:42:21,924 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:22,046 - src.parent_retriever - INFO - Processed 191/273 chunks (20 batches)\n",
      "2025-12-17 16:42:22,048 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:42:24,052 - src.parent_retriever - INFO - Document 'Kulbakov Nikolaj': 15 child chunks\n",
      "2025-12-17 16:42:24,183 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:24,559 - src.parent_retriever - INFO - Processed 206/273 chunks (21 batches)\n",
      "2025-12-17 16:42:24,562 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:42:26,565 - src.parent_retriever - INFO - Document 'Kuƒçerov√° Lucie': 4 child chunks\n",
      "2025-12-17 16:42:26,661 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:26,753 - src.parent_retriever - INFO - Processed 210/273 chunks (22 batches)\n",
      "2025-12-17 16:42:26,754 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:42:28,757 - src.parent_retriever - INFO - Document 'Leci√°n Michal': 8 child chunks\n",
      "2025-12-17 16:42:28,864 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:29,057 - src.parent_retriever - INFO - Processed 218/273 chunks (23 batches)\n",
      "2025-12-17 16:42:29,063 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:42:31,066 - src.parent_retriever - INFO - Document 'L√°tal Michael': 6 child chunks\n",
      "2025-12-17 16:42:31,155 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:31,241 - src.parent_retriever - INFO - Processed 224/273 chunks (24 batches)\n",
      "2025-12-17 16:42:31,243 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:42:33,246 - src.parent_retriever - INFO - Document 'Maru≈°√°k Jan': 6 child chunks\n",
      "2025-12-17 16:42:33,357 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:33,489 - src.parent_retriever - INFO - Processed 230/273 chunks (25 batches)\n",
      "2025-12-17 16:42:33,491 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:42:35,499 - src.parent_retriever - INFO - Document 'Nƒõmeƒçek Tom√°≈°': 28 child chunks\n",
      "2025-12-17 16:42:35,670 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:35,936 - src.parent_retriever - INFO - Processed 258/273 chunks (26 batches)\n",
      "2025-12-17 16:42:35,939 - src.parent_retriever - INFO - Waiting 2.0s before next batch...\n",
      "2025-12-17 16:42:37,941 - src.parent_retriever - INFO - Document 'Petr Jan': 15 child chunks\n",
      "2025-12-17 16:42:38,056 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:38,270 - src.parent_retriever - INFO - All 273 child chunks processed successfully in 27 batches\n",
      "2025-12-17 16:42:38,272 - src.parent_retriever - INFO - Parent retriever initialized successfully\n",
      "2025-12-17 16:42:38,298 - src.parent_retriever - INFO - Created 61 parent chunks and 298 child chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Retriever inicializov√°n\n",
      "\n",
      "Statistiky:\n",
      "  - Parent chunks: 61\n",
      "  - Child chunks: 298\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KROK 4: Inicializace Parent Document Retriever\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "retriever = CVParentRetriever(\n",
    "    config=config.rag,\n",
    "    vectorstore=vectorstore,\n",
    "    azure_config=config.azure\n",
    ")\n",
    "\n",
    "print(f\"\\nZpracov√°v√°m {len(documents)} dokument≈Ø...\")\n",
    "print(f\"Batch size: {config.azure.batch_size} chunks\")\n",
    "print(f\"Batch delay: {config.azure.batch_delay}s\\n\")\n",
    "\n",
    "# POZOR: Toto m≈Ø≈æe trvat nƒõkolik minut!\n",
    "# Vytv√°≈ô√≠ embeddingy pro v≈°echny child chunks\n",
    "retriever.initialize_retriever(documents)\n",
    "\n",
    "print(\"\\n‚úì Retriever inicializov√°n\")\n",
    "\n",
    "# Zkontroluj statistiky\n",
    "stats = retriever.get_stats()\n",
    "print(f\"\\nStatistiky:\")\n",
    "print(f\"  - Parent chunks: {stats['parent_chunks']}\")\n",
    "print(f\"  - Child chunks: {stats['child_chunks']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KONTROLA: Docstore na disku\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "docstore_path = Path(config.rag.persist_directory) / \"docstore\"\n",
    "\n",
    "print(f\"\\nDocstore cesta: {docstore_path}\")\n",
    "print(f\"Existuje: {docstore_path.exists()}\")\n",
    "\n",
    "if docstore_path.exists():\n",
    "    files = list(docstore_path.iterdir())\n",
    "    print(f\"Poƒçet soubor≈Ø: {len(files)}\")\n",
    "    \n",
    "    if len(files) > 0:\n",
    "        print(f\"\\nPrvn√≠ch 10 soubor≈Ø:\")\n",
    "        for i, file in enumerate(files[:10], 1):\n",
    "            size_kb = file.stat().st_size / 1024\n",
    "            print(f\"  {i}. {file.name} ({size_kb:.2f} KB)\")\n",
    "        \n",
    "        # Uk√°zka obsahu prvn√≠ho souboru\n",
    "        if files:\n",
    "            first_file = files[0]\n",
    "            print(f\"\\nObsah prvn√≠ho souboru ({first_file.name}):\")\n",
    "            content = first_file.read_text(encoding='utf-8')\n",
    "            print(content[:500] + \"...\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Docstore slo≈æka existuje, ale je PR√ÅZDN√Å!\")\n",
    "        print(\"   Tr√©nov√°n√≠ mo≈æn√° selhalo nebo je≈°tƒõ neprobƒõhlo.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Docstore slo≈æka NEEXISTUJE!\")\n",
    "    print(\"   Spus≈• initialize_retriever() pro vytvo≈ôen√≠.\")\n",
    "\n",
    "# √öpln√° cesta pro pr≈Øzkumn√≠k\n",
    "abs_path = docstore_path.absolute()\n",
    "print(f\"\\n√öpln√° cesta pro pr≈Øzkumn√≠k Windows:\")\n",
    "print(f\"{abs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'initialized',\n",
       " 'parent_chunks': 61,\n",
       " 'child_chunks': 298,\n",
       " 'parent_chunk_size': 2000,\n",
       " 'child_chunk_size': 400}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistiky po tr√©nov√°n√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Statistiky:\n",
      "  Parent chunks: 61\n",
      "  Child chunks: 298\n",
      "  Parent chunk size: 2000 znak≈Ø\n",
      "  Child chunk size: 400 znak≈Ø\n",
      "\n",
      "  Pr≈Ømƒõr child chunks na CV: 11.0\n",
      "  Pr≈Ømƒõr parent chunks na CV: 2.3\n"
     ]
    }
   ],
   "source": [
    "# Zobrazen√≠ statistik\n",
    "stats = retriever.get_stats()\n",
    "\n",
    "print(\"\\nüìä Statistiky:\")\n",
    "print(f\"  Parent chunks: {stats['parent_chunks']}\")\n",
    "print(f\"  Child chunks: {stats['child_chunks']}\")\n",
    "print(f\"  Parent chunk size: {stats['parent_chunk_size']} znak≈Ø\")\n",
    "print(f\"  Child chunk size: {stats['child_chunk_size']} znak≈Ø\")\n",
    "print(f\"\\n  Pr≈Ømƒõr child chunks na CV: {stats['child_chunks'] / len(documents):.1f}\")\n",
    "print(f\"  Pr≈Ømƒõr parent chunks na CV: {stats['parent_chunks'] / len(documents):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KROK 5: Test Retrieval\n",
    "\n",
    "Nyn√≠ m≈Ø≈æete testovat vyhled√°v√°n√≠ v natr√©novan√©m vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:38,365 - src.parent_retriever - INFO - Retrieving documents for query: 'candidates with Python skills' (top 3)\n",
      "2025-12-17 16:42:38,436 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:38,499 - src.parent_retriever - INFO - Retrieved 2 parent documents\n",
      "2025-12-17 16:42:38,500 - src.parent_retriever - INFO - Retrieving documents for query: 'who has AWS experience' (top 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KROK 5: Test Retrieval\n",
      "================================================================================\n",
      "\n",
      "üîç Dotaz: 'candidates with Python skills'\n",
      "--------------------------------------------------------------------------------\n",
      "Nalezeno 2 v√Ωsledk≈Ø:\n",
      "\n",
      "1. Bronec Ond≈ôej\n",
      "   D√©lka: 1953 znak≈Ø\n",
      "   Preview: www.dolphinconsulting.cz\t                Ing. Ond≈ôej Bronec  BI consultant    Prague    Key qualifications  Data mining and data science ‚Äì data cleaning, analysis, and modeling using Python and R or s...\n",
      "\n",
      "2. Hrd√Ω Daniel\n",
      "   D√©lka: 1937 znak≈Ø\n",
      "   Preview: www.dolphinconsulting.cz\t                Daniel Hrd√Ω  BI consultant   Prague, Czech Republic    Key qualifications  SQL procedures and queries, data modeling.  Data integration and transformation.  Us...\n",
      "\n",
      "\n",
      "üîç Dotaz: 'who has AWS experience'\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:38,645 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:38,662 - src.parent_retriever - INFO - Retrieved 2 parent documents\n",
      "2025-12-17 16:42:38,664 - src.parent_retriever - INFO - Retrieving documents for query: 'Java developers' (top 3)\n",
      "2025-12-17 16:42:38,746 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:38,766 - src.parent_retriever - INFO - Retrieved 3 parent documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nalezeno 2 v√Ωsledk≈Ø:\n",
      "\n",
      "1. Hu≈àa Tom√°≈°\n",
      "   D√©lka: 1997 znak≈Ø\n",
      "   Preview: www.dolphinconsulting.cz\t                Tom√°≈° Hu≈àa  DWH & Business Intelligence Consultant  Prague  Main Qualifications  Data modeling  Data integration  Cloud Solutions Design and Management  BI App...\n",
      "\n",
      "2. Bronec Ond≈ôej\n",
      "   D√©lka: 1953 znak≈Ø\n",
      "   Preview: www.dolphinconsulting.cz\t                Ing. Ond≈ôej Bronec  BI consultant    Prague    Key qualifications  Data mining and data science ‚Äì data cleaning, analysis, and modeling using Python and R or s...\n",
      "\n",
      "\n",
      "üîç Dotaz: 'Java developers'\n",
      "--------------------------------------------------------------------------------\n",
      "Nalezeno 3 v√Ωsledk≈Ø:\n",
      "\n",
      "1. Hu≈°ek Michal\n",
      "   D√©lka: 1996 znak≈Ø\n",
      "   Preview: www.dolphinconsulting.cz\t    Michal Hu≈°ek  BI Consultant & developer          Key qualifications  Full stack BI solutions development  .NET development      Skills & knowledge  Programming languages  ...\n",
      "\n",
      "2. Bukovsk√Ω Petr\n",
      "   D√©lka: 1927 znak≈Ø\n",
      "   Preview: www.dolphinconsulting.cz\t  Petr Bukovsk√Ω  DWH/BI Consultant    Brno    Key qualifications  Development ETL, data engineer  By education and previous experiences mechanical engineer specialized in FEA ...\n",
      "\n",
      "3. Bal√°ƒçek Daniel\n",
      "   D√©lka: 1995 znak≈Ø\n",
      "   Preview: www.dolphinconsulting.cz\t  Daniel Bal√°ƒçek  BI consultant    Praha    Key qualifications  Dashboard and report development and design  User requirements analysis and documentation  Business and data an...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KROK 5: Test Retrieval\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Testovac√≠ dotazy\n",
    "test_queries = [\n",
    "    \"candidates with Python skills\",\n",
    "    \"who has AWS experience\",\n",
    "    \"Java developers\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüîç Dotaz: '{query}'\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    results = retriever.retrieve(query, top_k=3)\n",
    "    \n",
    "    print(f\"Nalezeno {len(results)} v√Ωsledk≈Ø:\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        candidate_name = doc.metadata.get(\"candidate_name\", \"Unknown\")\n",
    "        content_preview = doc.page_content[:200].replace(\"\\n\", \" \")\n",
    "        \n",
    "        print(f\"{i}. {candidate_name}\")\n",
    "        print(f\"   D√©lka: {len(doc.page_content)} znak≈Ø\")\n",
    "        print(f\"   Preview: {content_preview}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vlastn√≠ testy\n",
    "\n",
    "Nyn√≠ m≈Ø≈æete zad√°vat vlastn√≠ dotazy a testovat retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:38,788 - src.parent_retriever - INFO - Retrieving documents for query: 'frontend developer with React' (top 5)\n",
      "2025-12-17 16:42:38,870 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Vlastn√≠ dotaz: 'frontend developer with React'\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:38,898 - src.parent_retriever - INFO - Retrieved 3 parent documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Bukovsk√Ω Petr\n",
      "--------------------------------------------------------------------------------\n",
      "www.dolphinconsulting.cz\t\n",
      "\n",
      "Petr Bukovsk√Ω\n",
      "\n",
      "DWH/BI Consultant \n",
      "\n",
      " Brno\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Development ETL, data engineer\n",
      "\n",
      "By education and previous experiences mechanical engineer specialized in FEA analysis and piping stress analyst in Oil and Gas industry\n",
      "\n",
      "\n",
      "\n",
      "Skills & knowledge\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "General\n",
      "\n",
      "Data modeling\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "Applications\n",
      "\n",
      "Tabidoo (including automation using JS)\n",
      "\n",
      "Microsoft Power BI and Power Query (basic knowledge)\n",
      "\n",
      "MS Excel (including VBA)\n",
      "\n",
      "ETL\n",
      "\n",
      "Data Factory, Python, Databricks\n",
      "\n",
      "Databases\n",
      "\n",
      "Microsoft SQL, MS Access\n",
      "\n",
      "Others\n",
      "\n",
      "Basic knowledge of HTML, CSS and network setup\n",
      "\n",
      "Python with packages for data analysis (Pandas, Numpy, Matplotlib, Seaborn)\n",
      "\n",
      "Javascript (scripting only)\n",
      "\n",
      "‚ÄãSEO optimization\n",
      "\n",
      "Git\n",
      "\n",
      "Languages\n",
      "\n",
      "Czech (native),\n",
      "\n",
      "English (B1/B2)\n",
      "\n",
      "German (A2)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selected project experience\n",
      "\n",
      "Period\n",
      "\n",
      "Customer\n",
      "\n",
      "Activities\n",
      "\n",
      "2025\n",
      "\n",
      "2024\n",
      "\n",
      "Skoda auto\n",
      "\n",
      "Data engineer ‚Äì analysis and data processing, ETL and DQ on Databricks platform (most often work with data from SAP environment)\n",
      "\n",
      "2023\n",
      "\n",
      "Dolphinconsulting\n",
      "\n",
      "Process design and implementation in IT management software ALVAO\n",
      "\n",
      "2023\n",
      "\n",
      "Dolphinconsulting\n",
      "\n",
      "Participation in the development of a system built on Azure Data Factory and Azure SQL.\n",
      "\n",
      "Advanced user settings and automation of data processing in the Tabidoo database application using Javascript.\n",
      "\n",
      "2023\n",
      "\n",
      "2022\n",
      "\n",
      "ThyssenKrupp Industrial Solutions (CZ)\n",
      "\n",
      "Design and development of a system for working with employee timesheets.\n",
      "\n",
      "ETL in Python.\n",
      "\n",
      "Automatic generation of reporting into created HTML templates along with distribution on servers.\n",
      "\n",
      "Parallel processing of data using Power BI.\n",
      "\n",
      "2022\n",
      "\n",
      "2021\n",
      "\n",
      "ThyssenKrupp Industrial Solutions (CZ)\n",
      "\n",
      "Design and development of a Python application to extend and clean up outputs from Hexagon Caesar II software.\n",
      "\n",
      "The application was further expanded with modules for specific engineering calculations.\n",
      "\n",
      "2019\n",
      "\n",
      "ThyssenKrupp Industrial Solutions (CZ)\n",
      "...\n",
      "\n",
      "2. Hlinkov√° Zuzana\n",
      "--------------------------------------------------------------------------------\n",
      "www.dolphinconsulting.cz\t\n",
      "\n",
      "Ing. Zuzana Hlinkova, M.A.\n",
      "\n",
      "BI consultant\n",
      "\n",
      " Prague\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Business Intelligence Developer/Data Analyst\n",
      "\n",
      "Qlik Sense, Spotfire\n",
      "\n",
      "Oracle SQL, Teradata\n",
      "\n",
      "JavaScript, HTML & CSS\n",
      "\n",
      "English: C1 ‚Äì C2 level\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skills & knowledge\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "General Skills\n",
      "\n",
      "Dashboard development and design\n",
      "\n",
      "Data modeling (BI tools, SQL)\n",
      "\n",
      "JavaScript, HTML & CSS\n",
      "\n",
      "User trainings\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "Applications\n",
      "\n",
      "Qlik Sense, NPrinting, Alerting\n",
      "\n",
      "Spotfire\n",
      "\n",
      "SAS Enterprise Guide and SAS Visual Analytics\n",
      "\n",
      "Databases\n",
      "\n",
      "Oracle\n",
      "\n",
      "Teradata\n",
      "\n",
      "Microsoft SQL\n",
      "\n",
      "Languages\n",
      "\n",
      "Czech (native), English (C2), French (B1-B2), Spanish (A1)\n",
      "\n",
      "\n",
      "Selected project experience\n",
      "\n",
      "Year\n",
      "\n",
      "Customer\n",
      "\n",
      "Activities\n",
      "\n",
      "2022 - 2023\n",
      "\n",
      "Menzies Aviation\n",
      "\n",
      "Business analysis and dashboard development in Qlik Sense and NPrinting for Cargo department. Release of global dashboards focusing on improving performance in several areas ‚Äì landside service, import breakdown and export expedition. \n",
      "\n",
      "User trainings, cooperation on migration of reporting from Qlik Sense to Power BI. \n",
      "\n",
      "2019 - 2022\n",
      "\n",
      "MSD IT\n",
      "\n",
      "Dashboard development in Spotfire and Qlik Sense. \n",
      "\n",
      "Involvement in creation of online trainings for business users and BI developers in Spotfire and Qlik Sense. \n",
      "\n",
      "Code review for other Qlik Sense projects.\n",
      "\n",
      "Custom visualization project ‚Äì development of custom visualizations for Spotfire and Qlik Sense in JavaScript (and D3 library). \n",
      "\n",
      "Spotfire SME role in data visualizations platform team.\n",
      "\n",
      "2018 - 2019\n",
      "\n",
      "Neit Consulting\n",
      "\n",
      "Working for several customers with different technologies. \n",
      "Mall CZ ‚Äì migration of BI DWH from MS SQL to Keboola\n",
      "MND a.s. - implementation of SAS ETRM for trading department, dashboard development in SAS VA and SAS EG.\n",
      "Ceska sporitelna ‚Äì dashboard development using SAS VA and Oracle SQL developer.\n",
      "\n",
      "2015 - 2018\n",
      "\n",
      "MND a.s.\n",
      "...\n",
      "\n",
      "3. Petr Jan\n",
      "--------------------------------------------------------------------------------\n",
      "www.dolphinconsulting.cz\t\n",
      "\n",
      "Jan Petr\n",
      "\n",
      "AI Engineer & BI Consultant\n",
      "\n",
      " Prague, Czechia\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "AI-Driven Solution Development & Agent System Architecture\n",
      "\n",
      "Data Pipeline Development & BI Visualization\n",
      "\n",
      "DevSecOps & Cloud Deployment\n",
      "\n",
      "Power BI Dashboard Development & DAX Implementation\n",
      "\n",
      "Cross-functional Collaboration & Project Management\n",
      "\n",
      "Performance Optimization & Analytics\n",
      "\n",
      "\n",
      "\n",
      "Skills & knowledge\n",
      "\n",
      "AI & Machine Learning\n",
      "\n",
      "Agent Systems: Autogen, LangChain, LangGraph, Multi-agent architectures, n8n\n",
      "\n",
      "LLM Integration: GPT-4 API, Azure OpenAI, Local model deployment (Llama, Phi)\n",
      "\n",
      "RAG & Retrieval: Vector strategies, theoretical knowledge and practical implementation\n",
      "\n",
      "Development: Python, Jupyter Notebooks, Model fine-tuning, Workflow automation\n",
      "\n",
      "DevSecOps & Infrastructure\n",
      "\n",
      "Containerization: Docker, Multi-environment deployment\n",
      "\n",
      "Azure Services: Azure DevOps, Container Registry, Container Instances, Virtual Machine\n",
      "\n",
      "Automation & Versioning: Bash scripting, Git version control, CI/CD fundamentals\n",
      "\n",
      "Authentication integration: OAuth2, Microsoft API\n",
      "\n",
      "Monitoring: Token usage tracking, Application logging\n",
      "\n",
      "Business Intelligence & Data\n",
      "\n",
      "BI Tools: MS Power BI & DAX, Looker Studio, MS Power Platform\n",
      "\n",
      "Data Processing: SQL, Python (NumPy, Pandas, Scikit-learn), MS Fabric, Power Query\n",
      "\n",
      "Visualization: Matplotlib, Seaborn, Plotly, Advanced dashboard development\n",
      "\n",
      "Analytics: ETL procedures, Data modeling, Exploratory Data Analysis\n",
      "\n",
      "Development & Integration\n",
      "\n",
      "Backend: Python, Flask, API development, Webhook implementation\n",
      "\n",
      "Frontend: Vue.js, Web UI development\n",
      "\n",
      "Database: SQL, Google BigQuery, IBM Watson Studio\n",
      "\n",
      "Project Management: GitHub versioning, Resource allocation, Task complexity estimation\n",
      "\n",
      "Languages\n",
      "\n",
      "Czech (native), English (active)\n",
      "\n",
      "AI and BI Projects\n",
      "\n",
      "Year\n",
      "\n",
      "Customer\n",
      "\n",
      "Activities\n",
      "\n",
      "2025 - Present\n",
      "\n",
      "dolphin consulting\n",
      "\n",
      "AI Solutions & Infrastructure Development\n",
      "\n",
      "HR Resume Processing System: Developed Flask-based multi-agent application using multi-agent framework Autogen\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Vlastn√≠ dotaz\n",
    "custom_query = \"frontend developer with React\"  # Zmƒõ≈àte podle pot≈ôeby\n",
    "\n",
    "print(f\"üîç Vlastn√≠ dotaz: '{custom_query}'\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = retriever.retrieve(custom_query, top_k=5)\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    candidate_name = doc.metadata.get(\"candidate_name\", \"Unknown\")\n",
    "    print(f\"\\n{i}. {candidate_name}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content[:5000])  # Prvn√≠ 500 znak≈Ø\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## s mƒõ≈ôen√≠m relevance retrievalu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST 1: Detekce relevance - Relevantn√≠ dotaz (Python developer)\n",
      "================================================================================\n",
      "\n",
      "Dotaz: \"Python developer with Django experience\"\n",
      "\n",
      "1a. Retrieve s scores (v≈°echny v√Ωsledky):\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:39,058 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:39,073 - src.parent_retriever - INFO - Retrieved 5 results with scores\n",
      "2025-12-17 16:42:39,080 - src.parent_retriever - INFO - Retrieving relevant documents for query: 'Python developer with Django experience' (top 5, threshold 1.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#   | Kandid√°t                       | Score      | Relevance\n",
      "--------------------------------------------------------------------------------\n",
      "1   | Bal√°ƒçek Daniel                 | 0.2978     | VYSOK√Å ‚úì‚úì‚úì\n",
      "2   | Hu≈àa Tom√°≈°                     | 0.3186     | VYSOK√Å ‚úì‚úì‚úì\n",
      "3   | Bukovsk√Ω Petr                  | 0.3240     | VYSOK√Å ‚úì‚úì‚úì\n",
      "4   | Petr Jan                       | 0.3396     | VYSOK√Å ‚úì‚úì‚úì\n",
      "5   | Bronec Ond≈ôej                  | 0.3410     | VYSOK√Å ‚úì‚úì‚úì\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1b. Retrieve relevant (s filtrem threshold=1.5):\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:39,147 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:39,185 - src.parent_retriever - INFO - Retrieved 5 relevant parent documents (filtered out 0 irrelevant results)\n",
      "2025-12-17 16:42:39,250 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:39,266 - src.parent_retriever - INFO - Retrieved 5 results with scores\n",
      "2025-12-17 16:42:39,274 - src.parent_retriever - INFO - Retrieving relevant documents for query: 'React frontend developer with GraphQL and TypeScript' (top 5, threshold 1.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nalezeno 5 relevantn√≠ch dokument≈Ø:\n",
      "  1. Bal√°ƒçek Daniel\n",
      "  2. Hu≈àa Tom√°≈°\n",
      "  3. Bukovsk√Ω Petr\n",
      "  4. Petr Jan\n",
      "  5. Bronec Ond≈ôej\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST 2: Detekce relevance - Irelevantn√≠ dotaz (React frontend)\n",
      "================================================================================\n",
      "\n",
      "Dotaz: \"React frontend developer with GraphQL and TypeScript\"\n",
      "(P≈ôedpokl√°d√°me, ≈æe nem√°me ≈æ√°dn√©ho React v√Ωvoj√°≈ôe)\n",
      "\n",
      "2a. Retrieve s scores (v≈°echny v√Ωsledky):\n",
      "------------------------------------------------------------\n",
      "\n",
      "#   | Kandid√°t                       | Score      | Relevance\n",
      "--------------------------------------------------------------------------------\n",
      "1   | Bukovsk√Ω Petr                  | 0.4267     | VYSOK√Å ‚úì‚úì‚úì\n",
      "2   | Petr Jan                       | 0.4382     | VYSOK√Å ‚úì‚úì‚úì\n",
      "3   | Nƒõmeƒçek Tom√°≈°                  | 0.4433     | VYSOK√Å ‚úì‚úì‚úì\n",
      "4   | Petr Jan                       | 0.4438     | VYSOK√Å ‚úì‚úì‚úì\n",
      "5   | Petr Jan                       | 0.4451     | VYSOK√Å ‚úì‚úì‚úì\n",
      "\n",
      "------------------------------------------------------------\n",
      "2b. Retrieve relevant (s filtrem threshold=1.5):\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:39,371 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:39,413 - src.parent_retriever - INFO - Retrieved 4 relevant parent documents (filtered out 0 irrelevant results)\n",
      "2025-12-17 16:42:39,501 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:39,507 - src.parent_retriever - INFO - Retrieved 3 results with scores\n",
      "2025-12-17 16:42:39,580 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:39,598 - src.parent_retriever - INFO - Retrieved 3 results with scores\n",
      "2025-12-17 16:42:39,609 - src.rag_chain - INFO - Initializing RAG Chain\n",
      "2025-12-17 16:42:39,614 - src.rag_chain - INFO - Creating LLM with deployment: gpt-4o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nalezeno 4 relevantn√≠ch dokument≈Ø\n",
      "  1. Bukovsk√Ω Petr\n",
      "  2. Petr Jan\n",
      "  3. Nƒõmeƒçek Tom√°≈°\n",
      "  4. Petr Jan\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST 3: Porovn√°n√≠ ƒçesk√© vs anglick√© query\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "Query (anglicky): \"Python developer\"\n",
      "============================================================\n",
      "\n",
      "Top 3 v√Ωsledky:\n",
      "  1. Bal√°ƒçek Daniel                 (score: 0.3234)\n",
      "  2. Hu≈àa Tom√°≈°                     (score: 0.3582)\n",
      "  3. Bronec Ond≈ôej                  (score: 0.3600)\n",
      "\n",
      "============================================================\n",
      "Query (ƒçesky): \"Python v√Ωvoj√°≈ô\"\n",
      "============================================================\n",
      "\n",
      "Top 3 v√Ωsledky:\n",
      "  1. Bal√°ƒçek Daniel                 (score: 0.3216)\n",
      "  2. Hu≈àa Tom√°≈°                     (score: 0.3399)\n",
      "  3. Bronec Ond≈ôej                  (score: 0.3755)\n",
      "\n",
      "üí° TIP: Anglick√© dotazy obvykle d√°vaj√≠ lep≈°√≠ scores\n",
      "   (ni≈æ≈°√≠ distance = vy≈°≈°√≠ podobnost)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST 4: RAG Chain s relevance filtrem\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:41,682 - src.rag_chain - INFO - RAG Chain created successfully\n",
      "2025-12-17 16:42:41,684 - src.rag_chain - INFO - Processing query: 'Python developer' (relevance_filter=True)\n",
      "2025-12-17 16:42:41,684 - src.parent_retriever - INFO - Retrieving relevant documents for query: 'Python developer' (top 5, threshold 1.5)\n",
      "2025-12-17 16:42:41,763 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:41,778 - src.parent_retriever - INFO - Retrieved 5 relevant parent documents (filtered out 0 irrelevant results)\n",
      "2025-12-17 16:42:41,780 - src.rag_chain - INFO - Retrieved 5 contexts\n",
      "2025-12-17 16:42:41,782 - src.parent_retriever - INFO - Retrieving documents for query: 'Python developer' (top 5)\n",
      "2025-12-17 16:42:41,880 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4a. Relevantn√≠ dotaz s filtrem:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:41,905 - src.parent_retriever - INFO - Retrieved 4 parent documents\n",
      "2025-12-17 16:42:52,087 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:52,120 - src.rag_chain - INFO - Answer generated successfully\n",
      "2025-12-17 16:42:52,123 - src.rag_chain - INFO - Processing query: 'React frontend developer' (relevance_filter=True)\n",
      "2025-12-17 16:42:52,125 - src.parent_retriever - INFO - Retrieving relevant documents for query: 'React frontend developer' (top 5, threshold 1.5)\n",
      "2025-12-17 16:42:52,321 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ot√°zka: Python developer\n",
      "Poƒçet kontext≈Ø: 5\n",
      "Odpovƒõƒè:\n",
      "Based on the provided CV excerpts, the candidates with Python development experience are:\n",
      "\n",
      "1. **Bal√°ƒçek Daniel** - Intermediate level in SQL and basic knowledge in Python.\n",
      "2. **Hu≈àa Tom√°≈°** - Basic knowledge in Python.\n",
      "3. **Bronec Ond≈ôej** - Extensive experience in Python, including packages such as Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, scikit-learn, SciPy, scikit-image, and PySpark. Also experienced in developing AI apps using Streamlit and Bot Framework SDK.\n",
      "4. **Bukovsk√Ω Petr** - Experience with Python for data analysis using packages like Pandas, Numpy, Matplotlib, and Seaborn. Also involved in ETL processes and developing Python applications for specific engineering calculations.\n",
      "\n",
      "Among these, **Bronec Ond≈ôej** has the most extensive and advanced experience in Python development.\n",
      "\n",
      "\n",
      "4b. Irelevantn√≠ dotaz s filtrem:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:52,355 - src.parent_retriever - INFO - Retrieved 4 relevant parent documents (filtered out 0 irrelevant results)\n",
      "2025-12-17 16:42:52,358 - src.rag_chain - INFO - Retrieved 4 contexts\n",
      "2025-12-17 16:42:52,366 - src.parent_retriever - INFO - Retrieving documents for query: 'React frontend developer' (top 5)\n",
      "2025-12-17 16:42:52,474 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:52,506 - src.parent_retriever - INFO - Retrieved 3 parent documents\n",
      "2025-12-17 16:42:53,120 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:53,125 - src.rag_chain - INFO - Answer generated successfully\n",
      "2025-12-17 16:42:53,129 - src.rag_chain - INFO - Processing query: 'React frontend developer' (relevance_filter=False)\n",
      "2025-12-17 16:42:53,132 - src.parent_retriever - INFO - Retrieving documents for query: 'React frontend developer' (top 5)\n",
      "2025-12-17 16:42:53,221 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:53,255 - src.parent_retriever - INFO - Retrieved 3 parent documents\n",
      "2025-12-17 16:42:53,262 - src.rag_chain - INFO - Retrieved 3 contexts\n",
      "2025-12-17 16:42:53,269 - src.parent_retriever - INFO - Retrieving documents for query: 'React frontend developer' (top 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ot√°zka: React frontend developer\n",
      "Poƒçet kontext≈Ø: 4\n",
      "No relevant results: False\n",
      "Odpovƒõƒè:\n",
      "I don't have enough information to answer this question. None of the provided CV excerpts mention experience or skills specifically related to React frontend development.\n",
      "\n",
      "\n",
      "4c. Irelevantn√≠ dotaz BEZ filtru (pro porovn√°n√≠):\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 16:42:53,409 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/text-embedding-ada-002-dolphin-1/embeddings?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:53,443 - src.parent_retriever - INFO - Retrieved 3 parent documents\n",
      "2025-12-17 16:42:53,807 - httpx - INFO - HTTP Request: POST https://oai-dolphin-1.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "2025-12-17 16:42:53,810 - src.rag_chain - INFO - Answer generated successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ot√°zka: React frontend developer\n",
      "Poƒçet kontext≈Ø: 3\n",
      "Odpovƒõƒè:\n",
      "I don't have enough information to answer this question.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "SHRNUT√ç\n",
      "================================================================================\n",
      "\n",
      "1. ‚úì Config: similarity_threshold = 1.5 (konfigurovateln√©)\n",
      "2. ‚úì Nov√° metoda: retriever.retrieve_relevant() \n",
      "   - Filtruje podle threshold\n",
      "   - Vrac√≠ jen relevantn√≠ v√Ωsledky (m≈Ø≈æe b√Ωt pr√°zdn√©!)\n",
      "3. ‚úì Vylep≈°en√Ω RAG chain: \n",
      "   - use_relevance_filter=True (default)\n",
      "   - Detekuje pr√°zdn√© v√Ωsledky\n",
      "   - Nepos√≠l√° irelevantn√≠ kontext do LLM\n",
      "4. ‚úì Lep≈°√≠ UX: \"No candidates found\" m√≠sto halucinac√≠\n",
      "\n",
      "TIP: Nastav threshold v config.py podle pot≈ôeby:\n",
      "  - < 1.0  = velmi p≈ô√≠sn√© (jen velmi podobn√©)\n",
      "  - 1.0-1.5 = standardn√≠ (dobr√© v√Ωsledky)\n",
      "  - > 1.5  = voln√© (v√≠ce v√Ωsledk≈Ø, ni≈æ≈°√≠ kvalita)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST 1: Detekce relevance - Relevantn√≠ dotaz (Python developer)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "relevant_query = \"Python developer with Django experience\"\n",
    "print(f\"\\nDotaz: \\\"{relevant_query}\\\"\\n\")\n",
    "\n",
    "# Test s scores\n",
    "print(\"1a. Retrieve s scores (v≈°echny v√Ωsledky):\")\n",
    "print(\"-\" * 60)\n",
    "results_with_scores = retriever.retrieve_with_scores(relevant_query, top_k=5)\n",
    "\n",
    "print(f\"\\n{'#':<3} | {'Kandid√°t':<30} | {'Score':<10} | Relevance\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, result in enumerate(results_with_scores, 1):\n",
    "    score = result.score\n",
    "    name = result.candidate_name\n",
    "    \n",
    "    # Urƒçen√≠ relevance podle score (distance metric - ni≈æ≈°√≠ = lep≈°√≠)\n",
    "    if score < 0.5:\n",
    "        relevance = \"VYSOK√Å ‚úì‚úì‚úì\"\n",
    "    elif score < 1.0:\n",
    "        relevance = \"ST≈òEDN√ç ‚úì‚úì\"\n",
    "    elif score < 1.5:\n",
    "        relevance = \"N√çZK√Å ‚úì\"\n",
    "    else:\n",
    "        relevance = \"IRELEVANTN√ç ‚úó\"\n",
    "    \n",
    "    print(f\"{i:<3} | {name:<30} | {score:<10.4f} | {relevance}\")\n",
    "\n",
    "# Test s filtrov√°n√≠m\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"1b. Retrieve relevant (s filtrem threshold=1.5):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "relevant_docs = retriever.retrieve_relevant(relevant_query, top_k=5)\n",
    "print(f\"\\nNalezeno {len(relevant_docs)} relevantn√≠ch dokument≈Ø:\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"  {i}. {doc.metadata.get('candidate_name', 'Unknown')}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"TEST 2: Detekce relevance - Irelevantn√≠ dotaz (React frontend)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "irrelevant_query = \"React frontend developer with GraphQL and TypeScript\"\n",
    "print(f\"\\nDotaz: \\\"{irrelevant_query}\\\"\")\n",
    "print(\"(P≈ôedpokl√°d√°me, ≈æe nem√°me ≈æ√°dn√©ho React v√Ωvoj√°≈ôe)\\n\")\n",
    "\n",
    "# Test s scores\n",
    "print(\"2a. Retrieve s scores (v≈°echny v√Ωsledky):\")\n",
    "print(\"-\" * 60)\n",
    "results_irrel = retriever.retrieve_with_scores(irrelevant_query, top_k=5)\n",
    "\n",
    "print(f\"\\n{'#':<3} | {'Kandid√°t':<30} | {'Score':<10} | Relevance\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, result in enumerate(results_irrel, 1):\n",
    "    score = result.score\n",
    "    name = result.candidate_name\n",
    "    \n",
    "    if score < 0.5:\n",
    "        relevance = \"VYSOK√Å ‚úì‚úì‚úì\"\n",
    "    elif score < 1.0:\n",
    "        relevance = \"ST≈òEDN√ç ‚úì‚úì\"\n",
    "    elif score < 1.5:\n",
    "        relevance = \"N√çZK√Å ‚úì\"\n",
    "    else:\n",
    "        relevance = \"IRELEVANTN√ç ‚úó\"\n",
    "    \n",
    "    print(f\"{i:<3} | {name:<30} | {score:<10.4f} | {relevance}\")\n",
    "\n",
    "# Test s filtrov√°n√≠m\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"2b. Retrieve relevant (s filtrem threshold=1.5):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "relevant_docs_irrel = retriever.retrieve_relevant(irrelevant_query, top_k=5)\n",
    "print(f\"\\nNalezeno {len(relevant_docs_irrel)} relevantn√≠ch dokument≈Ø\")\n",
    "\n",
    "if len(relevant_docs_irrel) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è ≈Ω√ÅDN√â relevantn√≠ v√Ωsledky!\")\n",
    "    print(\"   ‚Üí Spr√°vn√© chov√°n√≠: Nevr√°tit n√°hodn√© kandid√°ty\")\n",
    "else:\n",
    "    for i, doc in enumerate(relevant_docs_irrel, 1):\n",
    "        print(f\"  {i}. {doc.metadata.get('candidate_name', 'Unknown')}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"TEST 3: Porovn√°n√≠ ƒçesk√© vs anglick√© query\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "queries = [\n",
    "    (\"Python developer\", \"anglicky\"),\n",
    "    (\"Python v√Ωvoj√°≈ô\", \"ƒçesky\"),\n",
    "]\n",
    "\n",
    "for query, language in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query ({language}): \\\"{query}\\\"\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = retriever.retrieve_with_scores(query, top_k=3)\n",
    "    \n",
    "    print(f\"\\nTop 3 v√Ωsledky:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"  {i}. {result.candidate_name:<30} (score: {result.score:.4f})\")\n",
    "\n",
    "print(\"\\nüí° TIP: Anglick√© dotazy obvykle d√°vaj√≠ lep≈°√≠ scores\")\n",
    "print(\"   (ni≈æ≈°√≠ distance = vy≈°≈°√≠ podobnost)\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"TEST 4: RAG Chain s relevance filtrem\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Import RAG chain\n",
    "from src.rag_chain import CVRAGChain\n",
    "\n",
    "rag_chain = CVRAGChain(config.azure, retriever)\n",
    "\n",
    "# Test 1: Relevantn√≠ dotaz\n",
    "print(\"\\n4a. Relevantn√≠ dotaz s filtrem:\")\n",
    "print(\"-\" * 60)\n",
    "response1 = rag_chain.invoke(\"Python developer\", use_relevance_filter=True)\n",
    "print(f\"\\nOt√°zka: {response1.query}\")\n",
    "print(f\"Poƒçet kontext≈Ø: {response1.metadata['num_contexts']}\")\n",
    "print(f\"Odpovƒõƒè:\\n{response1.answer}\")\n",
    "\n",
    "# Test 2: Irelevantn√≠ dotaz\n",
    "print(\"\\n\\n4b. Irelevantn√≠ dotaz s filtrem:\")\n",
    "print(\"-\" * 60)\n",
    "response2 = rag_chain.invoke(\"React frontend developer\", use_relevance_filter=True)\n",
    "print(f\"\\nOt√°zka: {response2.query}\")\n",
    "print(f\"Poƒçet kontext≈Ø: {response2.metadata['num_contexts']}\")\n",
    "print(f\"No relevant results: {response2.metadata.get('no_relevant_results', False)}\")\n",
    "print(f\"Odpovƒõƒè:\\n{response2.answer}\")\n",
    "\n",
    "# Test 3: Irelevantn√≠ dotaz BEZ filtru (pro porovn√°n√≠)\n",
    "print(\"\\n\\n4c. Irelevantn√≠ dotaz BEZ filtru (pro porovn√°n√≠):\")\n",
    "print(\"-\" * 60)\n",
    "response3 = rag_chain.invoke(\"React frontend developer\", use_relevance_filter=False)\n",
    "print(f\"\\nOt√°zka: {response3.query}\")\n",
    "print(f\"Poƒçet kontext≈Ø: {response3.metadata['num_contexts']}\")\n",
    "print(f\"Odpovƒõƒè:\\n{response3.answer}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"SHRNUT√ç\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. ‚úì Config: similarity_threshold = 1.5 (konfigurovateln√©)\n",
    "2. ‚úì Nov√° metoda: retriever.retrieve_relevant() \n",
    "   - Filtruje podle threshold\n",
    "   - Vrac√≠ jen relevantn√≠ v√Ωsledky (m≈Ø≈æe b√Ωt pr√°zdn√©!)\n",
    "3. ‚úì Vylep≈°en√Ω RAG chain: \n",
    "   - use_relevance_filter=True (default)\n",
    "   - Detekuje pr√°zdn√© v√Ωsledky\n",
    "   - Nepos√≠l√° irelevantn√≠ kontext do LLM\n",
    "4. ‚úì Lep≈°√≠ UX: \"No candidates found\" m√≠sto halucinac√≠\n",
    "\n",
    "TIP: Nastav threshold v config.py podle pot≈ôeby:\n",
    "  - < 1.0  = velmi p≈ô√≠sn√© (jen velmi podobn√©)\n",
    "  - 1.0-1.5 = standardn√≠ (dobr√© v√Ωsledky)\n",
    "  - > 1.5  = voln√© (v√≠ce v√Ωsledk≈Ø, ni≈æ≈°√≠ kvalita)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ovƒõ≈ôen√≠ persistence\n",
    "\n",
    "Zkontrolujte, ≈æe data jsou ulo≈æena na disku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Soubory na disku:\n",
      "================================================================================\n",
      "\n",
      "Vector store directory: chroma_db\n",
      "  ‚úì Existuje\n",
      "  Soubory: 1 SQLite datab√°z√≠\n",
      "\n",
      "Docstore directory: chroma_db\\docstore\n",
      "  ‚úì Existuje\n",
      "  Soubory: 61 parent chunks\n",
      "\n",
      "‚úì V≈°echna data jsou ulo≈æena a lze je naƒç√≠st i po restartu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\nüìÅ Soubory na disku:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "persist_dir = Path(config.rag.persist_directory)\n",
    "docstore_dir = persist_dir / \"docstore\"\n",
    "\n",
    "print(f\"\\nVector store directory: {persist_dir}\")\n",
    "if persist_dir.exists():\n",
    "    print(f\"  ‚úì Existuje\")\n",
    "    chroma_files = list(persist_dir.glob(\"*.sqlite3\"))\n",
    "    print(f\"  Soubory: {len(chroma_files)} SQLite datab√°z√≠\")\n",
    "else:\n",
    "    print(f\"  ‚úó Neexistuje\")\n",
    "\n",
    "print(f\"\\nDocstore directory: {docstore_dir}\")\n",
    "if docstore_dir.exists():\n",
    "    print(f\"  ‚úì Existuje\")\n",
    "    docstore_files = list(docstore_dir.glob(\"*\"))\n",
    "    print(f\"  Soubory: {len(docstore_files)} parent chunks\")\n",
    "else:\n",
    "    print(f\"  ‚úó Neexistuje\")\n",
    "\n",
    "print(\"\\n‚úì V≈°echna data jsou ulo≈æena a lze je naƒç√≠st i po restartu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrnut√≠\n",
    "\n",
    "‚úÖ Training dokonƒçen!\n",
    "\n",
    "**Co bylo vytvo≈ôeno:**\n",
    "- ChromaDB vectorstore s child chunks (pro vyhled√°v√°n√≠)\n",
    "- LocalFileStore docstore s parent chunks (pro kontext)\n",
    "- Mapov√°n√≠ mezi child a parent chunks\n",
    "\n",
    "**V≈°e je ulo≈æeno na disku:**\n",
    "- `./chroma_db/` - ChromaDB datab√°ze\n",
    "- `./chroma_db/docstore/` - Parent chunks\n",
    "\n",
    "**Dal≈°√≠ kroky:**\n",
    "- Otev≈ôete `query.ipynb` pro testov√°n√≠ dotaz≈Ø\n",
    "- Nebo pou≈æijte `train.py` pro automatick√Ω training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jen vlastn√≠ hran√≠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "N√ÅHLED: Child chunks, kter√© p≈Øjdou do vectorstore\n",
      "================================================================================\n",
      "\n",
      "Uk√°zka child chunks pro prvn√≠ 2 dokumenty:\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìÑ CV: Bal√°ƒçek Daniel\n",
      "============================================================\n",
      "Poƒçet child chunks: 10\n",
      "\n",
      "Prvn√≠ch 3 child chunks:\n",
      "\n",
      "\n",
      "--- Child chunk 1/10 ---\n",
      "Velikost: 388 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bal√°ƒçek Daniel', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bal√°ƒçek_Daniel_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bal√°ƒçek_Daniel_CV_EN.docx', 'file_size': 496940, 'text_length': 3020}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "www.dolphinconsulting.cz\t\n",
      "\n",
      "Daniel Bal√°ƒçek\n",
      "\n",
      "BI consultant \n",
      "\n",
      " Praha\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Dashboard and report development and design\n",
      "\n",
      "User requirements analysis and documentation\n",
      "\n",
      "Business and data analysis\n",
      "\n",
      "\n",
      "\n",
      "Skills & knowledge\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "General Skills\n",
      "\n",
      "Dashboard and report developmen...\n",
      "\n",
      "\n",
      "--- Child chunk 2/10 ---\n",
      "Velikost: 386 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bal√°ƒçek Daniel', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bal√°ƒçek_Daniel_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bal√°ƒçek_Daniel_CV_EN.docx', 'file_size': 496940, 'text_length': 3020}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "Data modeling\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "Applications\n",
      "\n",
      "MS Excel - advanced\n",
      "\n",
      "Qlik Sense ‚Äì advanced \n",
      "\n",
      "Qlik NPrinting ‚Äì advanced\n",
      "\n",
      "Qlik Management Console ‚Äì advanced\n",
      "\n",
      "Qlik Alerting ‚Äì intermediate\n",
      "\n",
      "Qlik Forms - basic\n",
      "\n",
      "Power BI  ‚Äì basics\n",
      "\n",
      "Tableau ‚Äì basics\n",
      "\n",
      "GitHub ‚Äì basics\n",
      "\n",
      "Dataiku - basics\n",
      "\n",
      "Databases\n",
      "\n",
      "Micros...\n",
      "\n",
      "\n",
      "--- Child chunk 3/10 ---\n",
      "Velikost: 224 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bal√°ƒçek Daniel', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bal√°ƒçek_Daniel_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bal√°ƒçek_Daniel_CV_EN.docx', 'file_size': 496940, 'text_length': 3020}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "PowerDesigner\n",
      "\n",
      "Application Development\n",
      "\n",
      "SQL - intermediate\n",
      "\n",
      "Python - basics\n",
      "\n",
      "Languages\n",
      "\n",
      "Czech (native), English (advanced)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selected BI project experience\n",
      "\n",
      "Year\n",
      "\n",
      "Customer\n",
      "\n",
      "Activities\n",
      "\n",
      "2021-2024\n",
      "\n",
      "Ôøºdolphin consulting...\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìÑ CV: Bob≈Ørka Vojtƒõch\n",
      "============================================================\n",
      "Poƒçet child chunks: 7\n",
      "\n",
      "Prvn√≠ch 3 child chunks:\n",
      "\n",
      "\n",
      "--- Child chunk 1/7 ---\n",
      "Velikost: 390 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bob≈Ørka Vojtƒõch', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bob≈Ørka_Vojtƒõch_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bob≈Ørka_Vojtƒõch_CV_EN.docx', 'file_size': 543249, 'text_length': 2458}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "www.dolphinconsulting.cz\t\n",
      "\n",
      "Vojtƒõch Bob≈Ørka\n",
      "\n",
      "BI consultant \n",
      "\n",
      " Praha\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Dashboard and report development and design\n",
      "\n",
      "User requirements analysis and documentation\n",
      "\n",
      "Business and data analysis\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skills & knowledge\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "General Skills\n",
      "\n",
      "Dashboard and report develop...\n",
      "\n",
      "\n",
      "--- Child chunk 2/7 ---\n",
      "Velikost: 389 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bob≈Ørka Vojtƒõch', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bob≈Ørka_Vojtƒõch_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bob≈Ørka_Vojtƒõch_CV_EN.docx', 'file_size': 543249, 'text_length': 2458}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "Data modeling\n",
      "\n",
      "Data analysis\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "Applications\n",
      "\n",
      "Tibco Spotfire,\n",
      "\n",
      "Power BI, Power Apps, Power Automate,\n",
      "\n",
      "MS Excel\n",
      "\n",
      "Databases\n",
      "\n",
      "AWS Redshift, Teradata\n",
      "\n",
      "ETL\n",
      "\n",
      "SQL, Databrics, Dataiku, \n",
      "\n",
      "M, DAX, Power Query, Data Factory, Informatica\n",
      "\n",
      "Application Development\n",
      "\n",
      "SQL,\n",
      "\n",
      "HTML & CSS,\n",
      "\n",
      "IronPyth...\n",
      "\n",
      "\n",
      "--- Child chunk 3/7 ---\n",
      "Velikost: 321 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bob≈Ørka Vojtƒõch', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bob≈Ørka_Vojtƒõch_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bob≈Ørka_Vojtƒõch_CV_EN.docx', 'file_size': 543249, 'text_length': 2458}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "Languages\n",
      "\n",
      "Czech (native)\n",
      "\n",
      "English (fluent)\n",
      "\n",
      "German (basic)\n",
      "\n",
      "\n",
      "Selected project experience\n",
      "\n",
      "Year\n",
      "\n",
      "Customer\n",
      "\n",
      "Activities\n",
      "\n",
      "2024+\n",
      "\n",
      "MSD\n",
      "\n",
      "Core developer in MER IT team, responsible for building and maintaining MER data mart, data pipelines, supporting MER markets and reporting solutions in Qlik and Power B...\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìÑ CV: Bronec Ond≈ôej\n",
      "============================================================\n",
      "Poƒçet child chunks: 11\n",
      "\n",
      "Prvn√≠ch 3 child chunks:\n",
      "\n",
      "\n",
      "--- Child chunk 1/11 ---\n",
      "Velikost: 378 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bronec Ond≈ôej', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bronec_Ond≈ôej_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bronec_Ond≈ôej_CV_EN.docx', 'file_size': 595834, 'text_length': 3757}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "www.dolphinconsulting.cz\t\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ing. Ond≈ôej Bronec\n",
      "\n",
      "BI consultant \n",
      "\n",
      " Prague\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Data mining and data science ‚Äì data cleaning, analysis, and modeling using Python and R or specialized programs\n",
      "\n",
      "Machine learning and AI in Microsoft Azure and Microsoft Fabric with the code w...\n",
      "\n",
      "\n",
      "--- Child chunk 2/11 ---\n",
      "Velikost: 389 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bronec Ond≈ôej', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bronec_Ond≈ôej_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bronec_Ond≈ôej_CV_EN.docx', 'file_size': 595834, 'text_length': 3757}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "Prompt and context engineering experience through hands-on practice and by designing and delivering workshops\n",
      "\n",
      "Neural networks‚Äîtheory and applications; implemented custom models via transfer learning in Python\n",
      "\n",
      "Several years of reporting experience (TIBCO Spotfire)\n",
      "\n",
      "Authoring and publishing of AI-re...\n",
      "\n",
      "\n",
      "--- Child chunk 3/11 ---\n",
      "Velikost: 334 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bronec Ond≈ôej', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bronec_Ond≈ôej_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bronec_Ond≈ôej_CV_EN.docx', 'file_size': 595834, 'text_length': 3757}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "Skills & knowledge\n",
      "\n",
      "General knowledge\n",
      "\n",
      "Statistics, mathematics, neural networks, artificial intelligence, econometrics, economics, actuarial science\n",
      "\n",
      "Python (main packages)\n",
      "\n",
      "Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, scikit-learn, SciPy, scikit-image, PySpark\n",
      "\n",
      "R (main packages)\n",
      "\n",
      "caret, dplyr, g...\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìÑ CV: Bukovsk√Ω Petr\n",
      "============================================================\n",
      "Poƒçet child chunks: 8\n",
      "\n",
      "Prvn√≠ch 3 child chunks:\n",
      "\n",
      "\n",
      "--- Child chunk 1/8 ---\n",
      "Velikost: 364 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bukovsk√Ω Petr', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bukovsk√Ω_Petr_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bukovsk√Ω_Petr_CV_EN.docx', 'file_size': 544375, 'text_length': 2628}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "www.dolphinconsulting.cz\t\n",
      "\n",
      "Petr Bukovsk√Ω\n",
      "\n",
      "DWH/BI Consultant \n",
      "\n",
      " Brno\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Development ETL, data engineer\n",
      "\n",
      "By education and previous experiences mechanical engineer specialized in FEA analysis and piping stress analyst in Oil and Gas industry\n",
      "\n",
      "\n",
      "\n",
      "Skills & knowledge\n",
      "\n",
      "Business intellige...\n",
      "\n",
      "\n",
      "--- Child chunk 2/8 ---\n",
      "Velikost: 394 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bukovsk√Ω Petr', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bukovsk√Ω_Petr_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bukovsk√Ω_Petr_CV_EN.docx', 'file_size': 544375, 'text_length': 2628}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "Business intelligence\n",
      "\n",
      "Applications\n",
      "\n",
      "Tabidoo (including automation using JS)\n",
      "\n",
      "Microsoft Power BI and Power Query (basic knowledge)\n",
      "\n",
      "MS Excel (including VBA)\n",
      "\n",
      "ETL\n",
      "\n",
      "Data Factory, Python, Databricks\n",
      "\n",
      "Databases\n",
      "\n",
      "Microsoft SQL, MS Access\n",
      "\n",
      "Others\n",
      "\n",
      "Basic knowledge of HTML, CSS and network setup\n",
      "\n",
      "Python wit...\n",
      "\n",
      "\n",
      "--- Child chunk 3/8 ---\n",
      "Velikost: 352 znak≈Ø\n",
      "Metadata: {'candidate_name': 'Bukovsk√Ω Petr', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\Bukovsk√Ω_Petr_CV_EN.docx', 'type': 'cv_parent', 'filename': 'Bukovsk√Ω_Petr_CV_EN.docx', 'file_size': 544375, 'text_length': 2628}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "Javascript (scripting only)\n",
      "\n",
      "‚ÄãSEO optimization\n",
      "\n",
      "Git\n",
      "\n",
      "Languages\n",
      "\n",
      "Czech (native),\n",
      "\n",
      "English (B1/B2)\n",
      "\n",
      "German (A2)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Selected project experience\n",
      "\n",
      "Period\n",
      "\n",
      "Customer\n",
      "\n",
      "Activities\n",
      "\n",
      "2025\n",
      "\n",
      "2024\n",
      "\n",
      "Skoda auto\n",
      "\n",
      "Data engineer ‚Äì analysis and data processing, ETL and DQ on Databricks platform (most often work with...\n",
      "\n",
      "\n",
      "============================================================\n",
      "üìÑ CV: B√≠mov√° Kamila\n",
      "============================================================\n",
      "Poƒçet child chunks: 6\n",
      "\n",
      "Prvn√≠ch 3 child chunks:\n",
      "\n",
      "\n",
      "--- Child chunk 1/6 ---\n",
      "Velikost: 381 znak≈Ø\n",
      "Metadata: {'candidate_name': 'B√≠mov√° Kamila', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\B√≠mov√°_Kamila_CV_EN.docx', 'type': 'cv_parent', 'filename': 'B√≠mov√°_Kamila_CV_EN.docx', 'file_size': 512600, 'text_length': 2042}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "www.dolphinconsulting.cz\t\n",
      "\n",
      "Kamila B√≠mov√°\n",
      "\n",
      "Junior BI Consultant \n",
      "\n",
      " Praha\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Business analysis\n",
      "\n",
      "Implementation of DWH and BI solutions\n",
      "\n",
      "Development of ETL procedures\n",
      "\n",
      "Dashboard and report development and design\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skills & knowledge\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "General Skills\n",
      "\n",
      "Analysi...\n",
      "\n",
      "\n",
      "--- Child chunk 2/6 ---\n",
      "Velikost: 359 znak≈Ø\n",
      "Metadata: {'candidate_name': 'B√≠mov√° Kamila', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\B√≠mov√°_Kamila_CV_EN.docx', 'type': 'cv_parent', 'filename': 'B√≠mov√°_Kamila_CV_EN.docx', 'file_size': 512600, 'text_length': 2042}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "Dashboard and report development and design \n",
      "\n",
      "DWH architecture principles and principles of BI - basics\n",
      "\n",
      "ETL development - basics\n",
      "\n",
      "Business intelligence\n",
      "\n",
      "Applications\n",
      "\n",
      "Microsoft Excel, Power Query - advanced\n",
      "\n",
      "Microsoft Power BI - basics\n",
      "\n",
      "Databases\n",
      "\n",
      "Microsoft SQL Server - basics\n",
      "\n",
      "Application Developm...\n",
      "\n",
      "\n",
      "--- Child chunk 3/6 ---\n",
      "Velikost: 385 znak≈Ø\n",
      "Metadata: {'candidate_name': 'B√≠mov√° Kamila', 'source': '..\\\\data\\\\OneDrive_2025-12-16\\\\B√≠mov√°_Kamila_CV_EN.docx', 'type': 'cv_parent', 'filename': 'B√≠mov√°_Kamila_CV_EN.docx', 'file_size': 512600, 'text_length': 2042}\n",
      "\n",
      "Obsah (prvn√≠ch 300 znak≈Ø):\n",
      "SQL, T-SQL, M, DAX - basics\n",
      "\n",
      "Languages\n",
      "\n",
      "Czech (native), English (active, C1), German (passive, A2/B1)\n",
      "\n",
      "\n",
      "Selected project experience\n",
      "\n",
      "Year\n",
      "\n",
      "Customer\n",
      "\n",
      "Activities\n",
      "\n",
      "2021\n",
      "\n",
      "MSD\n",
      "\n",
      "Business Analysis of Cognos application development for Sales Department. Transformation of user requirements into technical spe...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CELKOV√ù P≈òEHLED - v≈°echny dokumenty\n",
      "================================================================================\n",
      "\n",
      "üìÑ Bal√°ƒçek Daniel                 ‚Üí  10 child chunks\n",
      "üìÑ Bob≈Ørka Vojtƒõch                ‚Üí   7 child chunks\n",
      "üìÑ Bronec Ond≈ôej                  ‚Üí  11 child chunks\n",
      "üìÑ Bukovsk√Ω Petr                  ‚Üí   8 child chunks\n",
      "üìÑ B√≠mov√° Kamila                  ‚Üí   6 child chunks\n",
      "üìÑ Dlugo≈°ov√° Lenka                ‚Üí   7 child chunks\n",
      "üìÑ Duleba Peter                   ‚Üí  10 child chunks\n",
      "üìÑ Fejfarov√° Julia                ‚Üí   5 child chunks\n",
      "üìÑ Fejfar Ond≈ôej                  ‚Üí   5 child chunks\n",
      "üìÑ Gleb Tcypin                    ‚Üí   8 child chunks\n",
      "üìÑ Hlavat√° Michaela               ‚Üí  17 child chunks\n",
      "üìÑ Hlinkov√° Zuzana                ‚Üí   8 child chunks\n",
      "üìÑ Holman Martin                  ‚Üí   5 child chunks\n",
      "üìÑ Hrd√Ω Daniel                    ‚Üí   7 child chunks\n",
      "üìÑ Hu≈àa Tom√°≈°                     ‚Üí  12 child chunks\n",
      "üìÑ Hu≈°ek Michal                   ‚Üí   7 child chunks\n",
      "üìÑ Karlovsk√Ω Luk√°≈°                ‚Üí  11 child chunks\n",
      "üìÑ Kol√°≈ô Petr                     ‚Üí  28 child chunks\n",
      "üìÑ Konvalinka Michal              ‚Üí   9 child chunks\n",
      "üìÑ Kub√°k Adam                     ‚Üí  10 child chunks\n",
      "üìÑ Kulbakov Nikolaj               ‚Üí  15 child chunks\n",
      "üìÑ Kuƒçerov√° Lucie                 ‚Üí   4 child chunks\n",
      "üìÑ Leci√°n Michal                  ‚Üí   8 child chunks\n",
      "üìÑ L√°tal Michael                  ‚Üí   6 child chunks\n",
      "üìÑ Maru≈°√°k Jan                    ‚Üí   6 child chunks\n",
      "üìÑ Nƒõmeƒçek Tom√°≈°                  ‚Üí  28 child chunks\n",
      "üìÑ Petr Jan                       ‚Üí  15 child chunks\n",
      "\n",
      "============================================================\n",
      "CELKEM: 273 child chunks p≈Øjde do vectorstore\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"N√ÅHLED: Child chunks, kter√© p≈Øjdou do vectorstore\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Vytvo≈ô splitters pro preview\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=config.rag.child_chunk_size,\n",
    "    chunk_overlap=config.rag.child_chunk_overlap,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Uk√°zka pro prvn√≠ 2 CVƒçka\n",
    "print(f\"\\nUk√°zka child chunks pro prvn√≠ 2 dokumenty:\\n\")\n",
    "\n",
    "for i, doc in enumerate(documents[:5]):\n",
    "    candidate_name = doc.metadata.get('candidate_name', 'Unknown')\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìÑ CV: {candidate_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split na child chunks\n",
    "    child_chunks = child_splitter.split_documents([doc])\n",
    "    \n",
    "    print(f\"Poƒçet child chunks: {len(child_chunks)}\")\n",
    "    print(f\"\\nPrvn√≠ch 3 child chunks:\\n\")\n",
    "    \n",
    "    for j, chunk in enumerate(child_chunks[:3]):\n",
    "        print(f\"\\n--- Child chunk {j+1}/{len(child_chunks)} ---\")\n",
    "        print(f\"Velikost: {len(chunk.page_content)} znak≈Ø\")\n",
    "        print(f\"Metadata: {chunk.metadata}\")\n",
    "        print(f\"\\nObsah (prvn√≠ch 300 znak≈Ø):\")\n",
    "        print(chunk.page_content[:300] + \"...\")\n",
    "        print()\n",
    "\n",
    "# Celkov√Ω p≈ôehled\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CELKOV√ù P≈òEHLED - v≈°echny dokumenty\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "total_child_chunks = 0\n",
    "for doc in documents:\n",
    "    candidate_name = doc.metadata.get('candidate_name', 'Unknown')\n",
    "    child_chunks = child_splitter.split_documents([doc])\n",
    "    num_chunks = len(child_chunks)\n",
    "    total_child_chunks += num_chunks\n",
    "    print(f\"üìÑ {candidate_name:30s} ‚Üí {num_chunks:3d} child chunks\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CELKEM: {total_child_chunks} child chunks p≈Øjde do vectorstore\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "N√ÅHLED: Parent + Child documents vztahy\n",
      "================================================================================\n",
      "\n",
      "Uk√°zka parent ‚Üí child vztah≈Ø pro prvn√≠ 2 dokumenty:\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìÑ CV: Bal√°ƒçek Daniel\n",
      "   P≈Øvodn√≠ velikost: 3020 znak≈Ø\n",
      "======================================================================\n",
      "\n",
      "‚Üí Rozdƒõleno na 2 parent chunks:\n",
      "\n",
      "  üì¶ Parent chunk 1/2\n",
      "     Velikost: 1995 znak≈Ø\n",
      "     ID: parent-0-1\n",
      "     ‚Üí Obsahuje 7 child chunks:\n",
      "        ‚îî‚îÄ Child 1: 388 znak≈Ø (parent_id: parent-0-1)\n",
      "        ‚îî‚îÄ Child 2: 386 znak≈Ø (parent_id: parent-0-1)\n",
      "        ‚îî‚îÄ Child 3: 224 znak≈Ø (parent_id: parent-0-1)\n",
      "        ‚îî‚îÄ Child 4: 260 znak≈Ø (parent_id: parent-0-1)\n",
      "        ‚îî‚îÄ Child 5: 241 znak≈Ø (parent_id: parent-0-1)\n",
      "        ‚îî‚îÄ Child 6: 391 znak≈Ø (parent_id: parent-0-1)\n",
      "        ‚îî‚îÄ Child 7: 241 znak≈Ø (parent_id: parent-0-1)\n",
      "\n",
      "     Obsah parent chunku (prvn√≠ch 200 znak≈Ø):\n",
      "     www.dolphinconsulting.cz\t\n",
      "\n",
      "Daniel Bal√°ƒçek\n",
      "\n",
      "BI consultant \n",
      "\n",
      " Praha\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Dashboard and report development and design\n",
      "\n",
      "User requirements analysis and documentation\n",
      "\n",
      "Business and data an...\n",
      "\n",
      "     Prvn√≠ child chunk z tohoto parent:\n",
      "     www.dolphinconsulting.cz\t\n",
      "\n",
      "Daniel Bal√°ƒçek\n",
      "\n",
      "BI consultant \n",
      "\n",
      " Praha\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Dashboard and report development and design\n",
      "\n",
      "User requirement...\n",
      "\n",
      "  üì¶ Parent chunk 2/2\n",
      "     Velikost: 1023 znak≈Ø\n",
      "     ID: parent-0-2\n",
      "     ‚Üí Obsahuje 3 child chunks:\n",
      "        ‚îî‚îÄ Child 1: 399 znak≈Ø (parent_id: parent-0-2)\n",
      "        ‚îî‚îÄ Child 2: 363 znak≈Ø (parent_id: parent-0-2)\n",
      "        ‚îî‚îÄ Child 3: 295 znak≈Ø (parent_id: parent-0-2)\n",
      "\n",
      "  CELKEM pro Bal√°ƒçek Daniel:\n",
      "    - 2 parent chunks\n",
      "    - 10 child chunks\n",
      "\n",
      "======================================================================\n",
      "üìÑ CV: Bob≈Ørka Vojtƒõch\n",
      "   P≈Øvodn√≠ velikost: 2458 znak≈Ø\n",
      "======================================================================\n",
      "\n",
      "‚Üí Rozdƒõleno na 2 parent chunks:\n",
      "\n",
      "  üì¶ Parent chunk 1/2\n",
      "     Velikost: 1970 znak≈Ø\n",
      "     ID: parent-1-1\n",
      "     ‚Üí Obsahuje 6 child chunks:\n",
      "        ‚îî‚îÄ Child 1: 390 znak≈Ø (parent_id: parent-1-1)\n",
      "        ‚îî‚îÄ Child 2: 389 znak≈Ø (parent_id: parent-1-1)\n",
      "        ‚îî‚îÄ Child 3: 321 znak≈Ø (parent_id: parent-1-1)\n",
      "        ‚îî‚îÄ Child 4: 390 znak≈Ø (parent_id: parent-1-1)\n",
      "        ‚îî‚îÄ Child 5: 360 znak≈Ø (parent_id: parent-1-1)\n",
      "        ‚îî‚îÄ Child 6: 227 znak≈Ø (parent_id: parent-1-1)\n",
      "\n",
      "     Obsah parent chunku (prvn√≠ch 200 znak≈Ø):\n",
      "     www.dolphinconsulting.cz\t\n",
      "\n",
      "Vojtƒõch Bob≈Ørka\n",
      "\n",
      "BI consultant \n",
      "\n",
      " Praha\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Dashboard and report development and design\n",
      "\n",
      "User requirements analysis and documentation\n",
      "\n",
      "Business and data a...\n",
      "\n",
      "     Prvn√≠ child chunk z tohoto parent:\n",
      "     www.dolphinconsulting.cz\t\n",
      "\n",
      "Vojtƒõch Bob≈Ørka\n",
      "\n",
      "BI consultant \n",
      "\n",
      " Praha\n",
      "\n",
      "\n",
      "\n",
      "Key qualifications\n",
      "\n",
      "Dashboard and report development and design\n",
      "\n",
      "User requiremen...\n",
      "\n",
      "  üì¶ Parent chunk 2/2\n",
      "     Velikost: 683 znak≈Ø\n",
      "     ID: parent-1-2\n",
      "     ‚Üí Obsahuje 2 child chunks:\n",
      "        ‚îî‚îÄ Child 1: 345 znak≈Ø (parent_id: parent-1-2)\n",
      "        ‚îî‚îÄ Child 2: 342 znak≈Ø (parent_id: parent-1-2)\n",
      "\n",
      "  CELKEM pro Bob≈Ørka Vojtƒõch:\n",
      "    - 2 parent chunks\n",
      "    - 8 child chunks\n",
      "\n",
      "================================================================================\n",
      "CELKOV√ù P≈òEHLED - v≈°echny dokumenty\n",
      "================================================================================\n",
      "\n",
      "CV jm√©no                       | Parents    | Children   | Children/Parent\n",
      "--------------------------------------------------------------------------------\n",
      "Bal√°ƒçek Daniel                 | 2          | 10         | 5.0\n",
      "Bob≈Ørka Vojtƒõch                | 2          | 8          | 4.0\n",
      "Bronec Ond≈ôej                  | 2          | 12         | 6.0\n",
      "Bukovsk√Ω Petr                  | 2          | 9          | 4.5\n",
      "B√≠mov√° Kamila                  | 2          | 7          | 3.5\n",
      "Dlugo≈°ov√° Lenka                | 2          | 9          | 4.5\n",
      "Duleba Peter                   | 2          | 10         | 5.0\n",
      "Fejfarov√° Julia                | 1          | 5          | 5.0\n",
      "Fejfar Ond≈ôej                  | 1          | 5          | 5.0\n",
      "Gleb Tcypin                    | 2          | 9          | 4.5\n",
      "Hlavat√° Michaela               | 3          | 17         | 5.7\n",
      "Hlinkov√° Zuzana                | 2          | 9          | 4.5\n",
      "Holman Martin                  | 1          | 5          | 5.0\n",
      "Hrd√Ω Daniel                    | 2          | 8          | 4.0\n",
      "Hu≈àa Tom√°≈°                     | 3          | 13         | 4.3\n",
      "Hu≈°ek Michal                   | 2          | 8          | 4.0\n",
      "Karlovsk√Ω Luk√°≈°                | 2          | 12         | 6.0\n",
      "Kol√°≈ô Petr                     | 6          | 33         | 5.5\n",
      "Konvalinka Michal              | 2          | 9          | 4.5\n",
      "Kub√°k Adam                     | 2          | 11         | 5.5\n",
      "Kulbakov Nikolaj               | 3          | 17         | 5.7\n",
      "Kuƒçerov√° Lucie                 | 1          | 4          | 4.0\n",
      "Leci√°n Michal                  | 2          | 8          | 4.0\n",
      "L√°tal Michael                  | 1          | 6          | 6.0\n",
      "Maru≈°√°k Jan                    | 2          | 7          | 3.5\n",
      "Nƒõmeƒçek Tom√°≈°                  | 6          | 31         | 5.2\n",
      "Petr Jan                       | 3          | 16         | 5.3\n",
      "--------------------------------------------------------------------------------\n",
      "CELKEM                         | 61         | 298        | 4.9\n",
      "\n",
      "================================================================================\n",
      "CO SE ULO≈Ω√ç:\n",
      "  - Vectorstore (ChromaDB): 298 child chunks (s embeddingy)\n",
      "  - Docstore (disk):        61 parent chunks (jako JSON)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"N√ÅHLED: Parent + Child documents vztahy\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Vytvo≈ô oba splitters\n",
    "parent_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=config.rag.parent_chunk_size,\n",
    "    chunk_overlap=config.rag.parent_chunk_overlap,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=config.rag.child_chunk_size,\n",
    "    chunk_overlap=config.rag.child_chunk_overlap,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Uk√°zka pro prvn√≠ 2 CVƒçka\n",
    "print(f\"\\nUk√°zka parent ‚Üí child vztah≈Ø pro prvn√≠ 2 dokumenty:\\n\")\n",
    "\n",
    "total_parents = 0\n",
    "total_children = 0\n",
    "\n",
    "for i, doc in enumerate(documents[:2]):\n",
    "    candidate_name = doc.metadata.get('candidate_name', 'Unknown')\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìÑ CV: {candidate_name}\")\n",
    "    print(f\"   P≈Øvodn√≠ velikost: {len(doc.page_content)} znak≈Ø\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # 1. Split na parent chunks\n",
    "    parent_chunks = parent_splitter.split_documents([doc])\n",
    "    num_parents = len(parent_chunks)\n",
    "    total_parents += num_parents\n",
    "    \n",
    "    print(f\"\\n‚Üí Rozdƒõleno na {num_parents} parent chunks:\")\n",
    "    \n",
    "    # 2. Pro ka≈æd√Ω parent chunk uk√°zat child chunks\n",
    "    doc_child_count = 0\n",
    "    for p_idx, parent in enumerate(parent_chunks, 1):\n",
    "        parent_id = f\"parent-{i}-{p_idx}\"  # Simulace ID\n",
    "        \n",
    "        # Split parent na child chunks\n",
    "        child_chunks = child_splitter.split_documents([parent])\n",
    "        num_children = len(child_chunks)\n",
    "        doc_child_count += num_children\n",
    "        total_children += num_children\n",
    "        \n",
    "        print(f\"\\n  üì¶ Parent chunk {p_idx}/{num_parents}\")\n",
    "        print(f\"     Velikost: {len(parent.page_content)} znak≈Ø\")\n",
    "        print(f\"     ID: {parent_id}\")\n",
    "        print(f\"     ‚Üí Obsahuje {num_children} child chunks:\")\n",
    "        \n",
    "        for c_idx, child in enumerate(child_chunks, 1):\n",
    "            print(f\"        ‚îî‚îÄ Child {c_idx}: {len(child.page_content)} znak≈Ø (parent_id: {parent_id})\")\n",
    "        \n",
    "        # Uk√°zka obsahu prvn√≠ho parent chunku\n",
    "        if p_idx == 1:\n",
    "            print(f\"\\n     Obsah parent chunku (prvn√≠ch 200 znak≈Ø):\")\n",
    "            print(f\"     {parent.page_content[:200]}...\")\n",
    "            \n",
    "            print(f\"\\n     Prvn√≠ child chunk z tohoto parent:\")\n",
    "            print(f\"     {child_chunks[0].page_content[:150]}...\")\n",
    "    \n",
    "    print(f\"\\n  CELKEM pro {candidate_name}:\")\n",
    "    print(f\"    - {num_parents} parent chunks\")\n",
    "    print(f\"    - {doc_child_count} child chunks\")\n",
    "\n",
    "# Celkov√Ω p≈ôehled pro v≈°echny dokumenty\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CELKOV√ù P≈òEHLED - v≈°echny dokumenty\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f\"{'CV jm√©no':<30} | {'Parents':<10} | {'Children':<10} | Children/Parent\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "grand_total_parents = 0\n",
    "grand_total_children = 0\n",
    "\n",
    "for doc in documents:\n",
    "    candidate_name = doc.metadata.get('candidate_name', 'Unknown')\n",
    "    \n",
    "    # Split na parents\n",
    "    parent_chunks = parent_splitter.split_documents([doc])\n",
    "    num_parents = len(parent_chunks)\n",
    "    \n",
    "    # Spoƒç√≠tej children\n",
    "    num_children = 0\n",
    "    for parent in parent_chunks:\n",
    "        child_chunks = child_splitter.split_documents([parent])\n",
    "        num_children += len(child_chunks)\n",
    "    \n",
    "    grand_total_parents += num_parents\n",
    "    grand_total_children += num_children\n",
    "    \n",
    "    ratio = num_children / num_parents if num_parents > 0 else 0\n",
    "    \n",
    "    print(f\"{candidate_name:<30} | {num_parents:<10} | {num_children:<10} | {ratio:.1f}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'CELKEM':<30} | {grand_total_parents:<10} | {grand_total_children:<10} | {grand_total_children/grand_total_parents:.1f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"CO SE ULO≈Ω√ç:\")\n",
    "print(f\"  - Vectorstore (ChromaDB): {grand_total_children} child chunks (s embeddingy)\")\n",
    "print(f\"  - Docstore (disk):        {grand_total_parents} parent chunks (jako JSON)\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RAG Training)",
   "language": "python",
   "name": "rag-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
