{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2: Advanced Retrieval Strategies\n",
                "\n",
                "In Part 1, we built a \"naive\" RAG pipeline. It works, but it has flaws:\n",
                "1. **Missed Context**: Splitting documents arbitrarily might cut a key idea in half.\n",
                "2. **Bad Access Patterns**: Searching for a specific keyword might miss a document that uses a synonym.\n",
                "3. **Distraction**: Retrieving 10 documents might confuse the LLM if only 1 is relevant (\"Lost in the Middle\" phenomenon).\n",
                "\n",
                "In this notebook, we fix these issues."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "51fc9ccc",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
                "from langchain_community.vectorstores import Chroma\n",
                "from langchain_community.document_loaders import TextLoader\n",
                "\n",
                "load_dotenv()\n",
                "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"https://VAS_RESOURCE_NAME.openai.azure.com/\")\n",
                "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"VAS_API_KEY\") # V prost≈ôed√≠ ƒçasto jako AZURE_OPENAI_API_KEY\n",
                "deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\") # N√°zev nasazen√≠ modelu (ne modelu samotn√©ho!)\n",
                "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\") \n",
                "\n",
                "# Inicializace Azure Embeddings\n",
                "embeddings = AzureOpenAIEmbeddings(\n",
                "    azure_endpoint=azure_endpoint,\n",
                "    api_key=api_key,\n",
                "    azure_deployment=deployment_name,\n",
                "    openai_api_version=api_version,\n",
                ")\n",
                "\n",
                "llm = AzureChatOpenAI(\n",
                "    azure_deployment=\"gpt-4o\",  # P≈ôedpokl√°d√°me, ≈æe n√°zev deploymentu v Azure je \"gpt-4o\"\n",
                "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\"),\n",
                "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
                "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
                "    temperature=0\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "facae52b",
            "metadata": {},
            "source": [
                "## 1. MultiQuery Retriever (Inteligentn√≠ roz≈°√≠≈ôen√≠ dotazu)\n",
                "\n",
                "**P≈ôedstavte si to jako**: Kdy≈æ nƒõco hled√°te na Googlu a na prvn√≠ pokus nenajdete to, co chcete, zkus√≠te dotaz p≈ôeformulovat. Zkus√≠te synonyma, odbornƒõj≈°√≠ v√Ωrazy nebo se zept√°te z jin√©ho √∫hlu. **MultiQuery Retriever** dƒõl√° p≈ôesnƒõ tohle za v√°s ‚Äì automaticky a okam≈æitƒõ.\n",
                "\n",
                "### üïµÔ∏è‚Äç‚ôÇÔ∏è V ƒçem je probl√©m? (Distance-based vector search)\n",
                "Vektorov√© datab√°ze hledaj√≠ dokumenty podle \"v√Ωznamov√© vzd√°lenosti\". Nƒõkdy se ale stane, ≈æe **slova u≈æivatele** a **slova v dokumentu** jsou p≈ô√≠li≈° odli≈°n√°, i kdy≈æ popisuj√≠ stejnou vƒõc.\n",
                "*   *U≈æivatel nap√≠≈°e:* \"Nefunguje √∫ƒçtov√°n√≠.\"\n",
                "*   *Dokument obsahuje:* \"Protokol pro ≈ôe≈°en√≠ transakƒçn√≠ch v√Ωjimek.\"\n",
                "\n",
                "Pokud polo≈æ√≠te jen jednu ot√°zku, m√°te jen **jeden pokus** trefit se do spr√°vn√©ho m√≠sta v datab√°zi. Pokud se netref√≠te, RAG sel≈æe.\n",
                "\n",
                "### üí° ≈òe≈°en√≠: \"Rozhozen√≠ ≈°ir≈°√≠ s√≠tƒõ\"\n",
                "M√≠sto toho, abychom poslali do datab√°ze jen v√°≈° jeden nedokonal√Ω dotaz, vyu≈æijeme pomoc LLM:\n",
                "\n",
                "1.  **Generov√°n√≠ variant**: LLM si vezme va≈°i ot√°zku a vymysl√≠ 3‚Äì5 r≈Øzn√Ωch zp≈Øsob≈Ø, jak se zeptat na to sam√© (pou≈æije synonyma, r≈Øzn√© perspektivy).\n",
                "2.  **Hromadn√© hled√°n√≠**: Spust√≠ se vyhled√°v√°n√≠ pro **KA≈ΩDOU** z tƒõchto variant zvl√°≈°≈•.\n",
                "3.  **Sjednocen√≠ (Unique Union)**: Syst√©m posb√≠r√° v≈°echny nalezen√© dokumenty ze v≈°ech dotaz≈Ø, odstran√≠ duplicity (ty, kter√© se na≈°ly v√≠cekr√°t) a vr√°t√≠ v√°m kompletn√≠ sadu.\n",
                "\n",
                "**P≈ô√≠klad z praxe:**\n",
                "*   **V√°≈° dotaz:** *\"How to handle server outages?\"*\n",
                "*   **Co udƒõl√° MultiQuery (na pozad√≠):** Vygeneruje a hled√° tak√©:\n",
                "    1.  *\"What are the protocols for system downtime?\"*\n",
                "    2.  *\"Emergency procedures for server failure\"*\n",
                "    3.  *\"Recovery steps during network incidents\"*\n",
                "\n",
                "D√≠ky tomu \"prohled√°te\" mnohem vƒõt≈°√≠ ƒç√°st datab√°ze a m√°te jistotu, ≈æe v√°m neunikne kl√≠ƒçov√Ω dokument jen kv≈Øli ≈°patnƒõ zvolen√©mu slov√≠ƒçku."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "142dc954",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚ùì P≈Øvodn√≠ dotaz: 'How to handle server outages?'\n",
                        "\n",
                        "--- 1. F√°ze: Generov√°n√≠ variant (Explicitn√≠ spu≈°tƒõn√≠) ---\n",
                        "['What are the best practices for managing server downtime?', 'How can I effectively deal with server outages?', 'What strategies can be used to handle server failures?']\n",
                        "\n",
                        "--- 2. F√°ze: Samotn√© vyhled√°v√°n√≠ dokument≈Ø ---\n",
                        "‚úÖ Nalezeno 4 unik√°tn√≠ch dokument≈Ø.\n",
                        "   [1] SERVICE LEVEL AGREEMENT (SLA) for NebulaDB Enterprise\n",
                        "\n",
                        "1. DEFINITIONS\n",
                        "\"Uptime\" r... (Zdroj: ../data/legal/sla_contract.txt)\n",
                        "   [2] 4. EXCLUSIONS\n",
                        "The Service Commitment does not apply to any unavailability, suspe... (Zdroj: ../data/legal/sla_contract.txt)\n",
                        "   [3] Quarter: Q2 2024\n",
                        "Revenue: 1200000\n",
                        "Expenses: 850000\n",
                        "Profit: 350000\n",
                        "Notes: cost op... (Zdroj: ../data/finance/financial_report.csv)\n",
                        "   [4] 3. SERVICE CREDITS\n",
                        "If we do not meet the Service Commitment, you will be eligibl... (Zdroj: ../data/legal/sla_contract.txt)\n",
                        "\n",
                        "--- 3. F√°ze: Generov√°n√≠ fin√°ln√≠ odpovƒõdi (LCEL RAG Chain) ---\n",
                        "Ot√°zka: How to handle server outages?\n",
                        "------------------------------\n",
                        "Odpovƒõƒè: To handle server outages in the context of the NebulaDB Enterprise Service Level Agreement (SLA), you should follow these steps:\n",
                        "\n",
                        "1. **Identify the Outage**: Determine if the outage qualifies as \"Downtime\" by checking if the Error Rate is greater than 5% for a period exceeding 5 minutes.\n",
                        "\n",
                        "2. **Check Uptime**: Calculate the Monthly Uptime Percentage to see if it falls below the committed 99.99%.\n",
                        "\n",
                        "3. **Review Exclusions**: Ensure that the outage is not caused by factors outside of NebulaDB's reasonable control, such as force majeure events or Internet access issues beyond NebulaDB's demarcation point.\n",
                        "\n",
                        "4. **Submit a Claim**: If the outage qualifies and is not excluded, submit a claim for a Service Credit by opening a case in the NebulaDB Support Center within 30 days of the incident.\n",
                        "\n",
                        "5. **Service Credits**: Based on the Monthly Uptime Percentage, determine the eligible Service Credit:\n",
                        "   - If Uptime is < 99.99% but >= 99.0%, you are eligible for a 10% Credit.\n",
                        "   - If Uptime is < 99.0% but >= 95.0%, you are eligible for a 25% Credit.\n",
                        "   - If Uptime is < 95.0%, you are eligible for a 100% Credit.\n",
                        "\n",
                        "By following these steps, you can effectively handle server outages and ensure you receive the appropriate Service Credits as per the SLA.\n"
                    ]
                }
            ],
            "source": [
                "# 1. Inicializace (jako doposud)\n",
                "# Ujistƒõte se, ≈æe vectorstore je spr√°vnƒõ naƒçten√Ω s persist_directory=\"../chroma_db\"\n",
                "try:\n",
                "    from langchain.retrievers.multi_query import MultiQueryRetriever\n",
                "except ImportError:\n",
                "    from langchain_classic.retrievers import MultiQueryRetriever\n",
                "\n",
                "retriever_mq = MultiQueryRetriever.from_llm(\n",
                "    retriever=vectorstore.as_retriever(),\n",
                "    llm=llm\n",
                ")\n",
                "\n",
                "question = \"How to handle server outages?\"\n",
                "\n",
                "# --- FUNKƒåN√ç ANAL√ùZA ---\n",
                "print(f\"‚ùì P≈Øvodn√≠ dotaz: '{question}'\")\n",
                "print(\"\\n--- 1. F√°ze: Generov√°n√≠ variant (Explicitn√≠ spu≈°tƒõn√≠) ---\")\n",
                "\n",
                "# Zde si \"vyt√°hneme\" vnit≈ôn√≠ ≈ôetƒõzec, kter√Ω m√° na starosti pouze generov√°n√≠\n",
                "# a spust√≠me ho samostatnƒõ, abychom vidƒõli v√Ωsledek.\n",
                "if hasattr(retriever_mq, \"llm_chain\"):\n",
                "    # Spu≈°tƒõn√≠ generov√°n√≠\n",
                "    variants_result = retriever_mq.llm_chain.invoke({\"question\": question})\n",
                "    \n",
                "    # V√Ωsledek m≈Ø≈æe b√Ωt objekt nebo slovn√≠k, vytiskneme text\n",
                "    if isinstance(variants_result, dict) and \"text\" in variants_result:\n",
                "        print(variants_result[\"text\"])\n",
                "    else:\n",
                "        print(variants_result)\n",
                "else:\n",
                "    print(\"‚ùå Nepoda≈ôilo se nal√©zt atribut 'llm_chain'.\")\n",
                "\n",
                "print(\"\\n--- 2. F√°ze: Samotn√© vyhled√°v√°n√≠ dokument≈Ø ---\")\n",
                "# Nyn√≠ probƒõhne standardn√≠ proces (znovu si vygeneruje ot√°zky a vyhled√° je)\n",
                "docs = retriever_mq.invoke(question)\n",
                "\n",
                "print(f\"‚úÖ Nalezeno {len(docs)} unik√°tn√≠ch dokument≈Ø.\")\n",
                "for i, d in enumerate(docs):\n",
                "    print(f\"   [{i+1}] {d.page_content[:80]}... (Zdroj: {d.metadata.get('source', 'N/A')})\")\n",
                "\n",
                "from langchain_core.runnables import RunnablePassthrough\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "\n",
                "print(\"\\n--- 3. F√°ze: Generov√°n√≠ fin√°ln√≠ odpovƒõdi (LCEL RAG Chain) ---\")\n",
                "\n",
                "# A. Prompt (Instrukce pro model)\n",
                "template = \"\"\"Answer the question based only on the following context:\n",
                "{context}\n",
                "\n",
                "Question: {question}\n",
                "\"\"\"\n",
                "prompt = ChatPromptTemplate.from_template(template)\n",
                "\n",
                "# B. Pomocn√° funkce pro zform√°tov√°n√≠ dokument≈Ø do textu\n",
                "def format_docs(docs):\n",
                "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
                "\n",
                "# C. Sestaven√≠ RAG ≈ôetƒõzce (Chain)\n",
                "# ZMƒöNA: M√≠sto 'retriever' pou≈æijeme n√°≈° 'retriever_mq'\n",
                "rag_chain_from_multiquery = (\n",
                "    {\"context\": retriever_mq | format_docs, \"question\": RunnablePassthrough()}\n",
                "    | prompt\n",
                "    | llm\n",
                "    | StrOutputParser()\n",
                ")\n",
                "\n",
                "# D. Spu≈°tƒõn√≠\n",
                "# .invoke() spust√≠ cel√Ω proces: MultiQuery vyhled√°v√°n√≠ (s 3-5 variantami) -> form√°tov√°n√≠ -> prompt -> GPT\n",
                "print(f\"Ot√°zka: {question}\")\n",
                "print(\"-\" * 30)\n",
                "response = rag_chain_from_multiquery.invoke(question)\n",
                "print(\"Odpovƒõƒè:\", response)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f5c63757",
            "metadata": {},
            "source": [
                "## 2. Parent Document Retriever (Mal√Ω detektiv, Velk√Ω ƒçten√°≈ô)\n",
                "\n",
                "Abychom pochopili, proƒç tuto techniku pot≈ôebujeme, mus√≠me si nejd≈ô√≠ve uk√°zat, kde **klasick√Ω RAG selh√°v√°**.\n",
                "\n",
                "### 1. Klasick√Ω p≈ô√≠stup (Bez Parent Retrieveru)\n",
                "V klasick√©m RAGu dƒõl√°te kompromis. Mus√≠te se rozhodnout pro jednu velikost kousk≈Ø (chunks) pro v≈°echno.\n",
                "*   Jeden chunk slou≈æ√≠ k tomu, aby byl **nalezen** (vyhled√°v√°n√≠).\n",
                "*   TEN SAM√ù chunk se po≈°le LLM, aby z nƒõj **odpovƒõdƒõlo** (generov√°n√≠).\n",
                "\n",
                "**Dilema:**\n",
                "*   **Kdy≈æ udƒõl√°te chunks mal√© (nap≈ô. 1 vƒõta):**\n",
                "    *   ‚úÖ **Vyhled√°v√°n√≠ je super:** Kdy≈æ u≈æivatel hled√° *\"cena podpory\"*, poƒç√≠taƒç to snadno najde, proto≈æe ve vƒõtƒõ *\"Cena podpory je 500 Kƒç\"* tvo≈ô√≠ tato slova 50 % obsahu. Je to jasn√Ω sign√°l.\n",
                "    *   ‚ùå **LLM sel≈æe:** Modelu po≈°lete jen tu jednu vƒõtu: *\"Cena podpory je 500 Kƒç\"*. LLM se zept√°: *\"Aha, a jak√© podpory? Mƒõs√≠ƒçn√≠? Roƒçn√≠? Pro koho?\"* Chyb√≠ mu **kontext**.\n",
                "\n",
                "*   **Kdy≈æ udƒõl√°te chunks velk√© (nap≈ô. cel√° str√°nka):**\n",
                "    *   ‚úÖ **LLM je spokojen√©:** Vid√≠ celou str√°nku, v√≠, ≈æe jde o *\"NebulaDB Enterprise roƒçn√≠ pl√°n\"*. M√° kontext.\n",
                "    *   ‚ùå **Vyhled√°v√°n√≠ sel≈æe:** Ve velk√© str√°nce textu se slova *\"cena podpory\"* ztrat√≠. Tvo≈ô√≠ t≈ôeba jen 1 % textu. Vektorov√° podobnost bude n√≠zk√° a datab√°ze tento dokument v≈Øbec nenajde (tzv. \"utopen√≠ jehly v kupce sena\").\n",
                "\n",
                "### 2. ≈òe≈°en√≠: Parent Document Retriever\n",
                "Tato metoda **oddƒõluje** to, co hled√°me, od toho, co ƒçte LLM.\n",
                "\n",
                "1.  **Indexujeme \"Dƒõti\" (Small Chunks):** Dokument rozsek√°me na maliƒçk√© kousky (nap≈ô. 100 znak≈Ø). Ty pou≈æijeme **POUZE pro vyhled√°v√°n√≠**. D√≠ky tomu je hled√°n√≠ extr√©mnƒõ citliv√© a p≈ôesn√©.\n",
                "2.  **Ukl√°d√°me \"Rodiƒçe\" (Large Chunks):** Z√°rove≈à si pamatujeme, ≈æe tyto mal√© kousky pat≈ô√≠ do vƒõt≈°√≠ho bloku (nap≈ô. 500 znak≈Ø nebo cel√° str√°nka).\n",
                "3.  **Proces:**\n",
                "    *   U≈æivatel hled√° *\"cena\"*.\n",
                "    *   Datab√°ze najde mal√Ω kousek (D√≠tƒõ): *\"Cena je 500 Kƒç\"*.\n",
                "    *   Retriever ale nevr√°t√≠ toto d√≠tƒõ. Pod√≠v√° se, kdo je jeho rodiƒç.\n",
                "    *   LLM po≈°le cel√©ho rodiƒçe: *\"Cen√≠k pro rok 2024. Slu≈æba NebulaDB. Z√°kladn√≠ cena je zdarma. Cena pr√©miov√© podpory je 500 Kƒç mƒõs√≠ƒçnƒõ p≈ôi √∫vazku na rok.\"*\n",
                "\n",
                "### 3. Proƒç \"LLM funguje l√©pe s velk√Ωmi kousky\"?\n",
                "Pt√°te se spr√°vnƒõ: *\"LLM se pou≈æ√≠v√° v≈ædy, ne?\"*\n",
                "Ano, ale LLM je jako **kucha≈ô**. Jeho j√≠dlo (odpovƒõƒè) je jen tak dobr√©, jak dobr√© jsou **suroviny** (kontext), kter√© mu dod√°te.\n",
                "\n",
                "*   **P≈ô√≠klad:** U≈æivatel se zept√°: *\"Co se stane p≈ôi v√Ωpadku?\"*\n",
                "*   **Vstup pro LLM (bez Parent Retrieveru - mal√Ω chunk):**\n",
                "    > *\"Dostanete kredit 10 %.\"*\n",
                "    *   *V√Ωsledek:* LLM odpov√≠: \"Dostanete 10% kredit.\" (Nev√≠ za co, nev√≠ komu).\n",
                "*   **Vstup pro LLM (s Parent Retrieverem - velk√Ω chunk):**\n",
                "    > *\"3. KOMPENZACE. Pokud dostupnost klesne pod 99.9%, z√°kazn√≠k m√° n√°rok na kompenzaci. U v√Ωpadku nad 1 hodinu dostanete kredit 10 % z mƒõs√≠ƒçn√≠ platby.\"*\n",
                "    *   *V√Ωsledek:* LLM odpov√≠: \"Pokud v√Ωpadek trv√° d√©le ne≈æ hodinu a dostupnost klesne pod 99.9 %, m√°te n√°rok na kredit ve v√Ω≈°i 10 % z mƒõs√≠ƒçn√≠ platby.\"\n",
                "\n",
                "**Z√°vƒõr:** Parent Document Retriever n√°m d√°v√° to nejlep≈°√≠ z obou svƒõt≈Ø: **P≈ôesnost vyhled√°v√°n√≠** v mal√Ωch datech a **bohatost kontextu** ve velk√Ωch datech."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "id": "ee3bd938",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Indexuji dokumenty ---\n",
                        "Indexov√°no 1 p≈Øvodn√≠ dokument≈Ø.\n",
                        "\n",
                        "‚ùì Hled√°m dotaz: 'rate limits'\n",
                        "‚úÖ Nalezeno dokument≈Ø: 1\n",
                        "   D√©lka vr√°cen√©ho obsahu: 143 znak≈Ø\n",
                        "   Uk√°zka obsahu (Rodiƒç):\n",
                        "--------------------\n",
                        "## Error Codes\n",
                        "- `400`: Invalid parameters (e.g., node_count < 3).\n",
                        "- `401`: unauthorized.\n",
                        "- `429`: Rate limit exceeded (100 req/sec per token).\n",
                        "--------------------\n"
                    ]
                }
            ],
            "source": [
                "from langchain_classic.retrievers import ParentDocumentRetriever\n",
                "from langchain_classic.storage import InMemoryStore\n",
                "# Pou≈æ√≠v√°me modern√≠ cestu pro splittery\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "from langchain_community.document_loaders import TextLoader\n",
                "\n",
                "# 1. P≈ô√≠prava √∫lo≈æi≈°≈•\n",
                "# Vectorstore (Chroma) bude dr≈æet jen \"mal√© dƒõti\" (vektory)\n",
                "# Docstore (InMemory) bude dr≈æet \"velk√© rodiƒçe\" (cel√Ω text)\n",
                "vectorstore_parent = Chroma(\n",
                "    collection_name=\"rag_parent\", \n",
                "    embedding_function=embeddings,\n",
                "    # Tady nepou≈æ√≠v√°me persistenci na disk pro zjednodu≈°en√≠ uk√°zky, \n",
                "    # ale v praxi byste chtƒõli i 'store' ukl√°dat (nap≈ô. RedisStore).\n",
                ")\n",
                "store = InMemoryStore()\n",
                "\n",
                "# 2. Nastaven√≠ Splitter≈Ø (Dƒõlen√≠ textu)\n",
                "# \"Rodiƒç\" - vƒõt≈°√≠ bloky (nap≈ô. 500 znak≈Ø), kter√© chce ƒç√≠st LLM\n",
                "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100)\n",
                "# \"D√≠tƒõ\" - mal√© √∫tr≈æky (nap≈ô. 100 znak≈Ø), kter√© slou≈æ√≠ jen pro vyhled√°n√≠\n",
                "child_splitter = RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=50)\n",
                "\n",
                "# 3. Inicializace Retrieveru\n",
                "retriever_parent = ParentDocumentRetriever(\n",
                "    vectorstore=vectorstore_parent, \n",
                "    docstore=store, \n",
                "    child_splitter=child_splitter,  # Podle tohoto se hled√°\n",
                "    parent_splitter=parent_splitter # Toto se vrac√≠ do promptu\n",
                ")\n",
                "\n",
                "# 4. Naƒçten√≠ dat a indexace\n",
                "print(\"--- Indexuji dokumenty ---\")\n",
                "# Naƒçteme n√°≈° Markdown soubor\n",
                "loader = TextLoader(\"../data/tech_docs/api_docs.md\")\n",
                "docs = loader.load()\n",
                "\n",
                "# Tady se dƒõje kouzlo: add_documents samo rozsek√° text na mal√© i velk√© kusy a propoj√≠ je\n",
                "retriever_parent.add_documents(docs)\n",
                "print(f\"Indexov√°no {len(docs)} p≈Øvodn√≠ dokument≈Ø.\")\n",
                "\n",
                "# 5. Test vyhled√°v√°n√≠\n",
                "query = \"rate limits\"\n",
                "print(f\"\\n‚ùì Hled√°m dotaz: '{query}'\")\n",
                "\n",
                "# Pou≈æijeme .invoke()\n",
                "results = retriever_parent.invoke(query)\n",
                "\n",
                "if len(results) > 0:\n",
                "    print(f\"‚úÖ Nalezeno dokument≈Ø: {len(results)}\")\n",
                "    print(f\"   D√©lka vr√°cen√©ho obsahu: {len(results[0].page_content)} znak≈Ø\")\n",
                "    print(f\"   Uk√°zka obsahu (Rodiƒç):\")\n",
                "    print(\"-\" * 20)\n",
                "    print(results[0].page_content)\n",
                "    print(\"-\" * 20)\n",
                "else:\n",
                "    print(\"‚ùå Nic nenalezeno.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Contextual Compression (Destilace informac√≠)\n",
                "\n",
                "Tato technika ≈ôe≈°√≠ probl√©m **\"informaƒçn√≠ho ≈°umu\"**.\n",
                "\n",
                "### 1. Probl√©m: Vektorov√© hled√°n√≠ je \"hloup√©\"\n",
                "Vektorov√° datab√°ze je velmi rychl√°, ale neum√≠ ƒç√≠st. Porovn√°v√° pouze matematickou podobnost vektor≈Ø.\n",
                "*   **P≈ô√≠klad:** Hled√°te *\"Jakou dostanu slevu za v√Ωpadek?\"*\n",
                "*   **Vector Store najde:** *\"Kompenzace (slevy) se nevztahuj√≠ na pl√°novan√© v√Ωpadky √∫dr≈æby...\"*\n",
                "    *   Matematicky je to velmi podobn√° vƒõta (obsahuje slova *v√Ωpadek, sleva*).\n",
                "    *   Fakticky je to ale **opak** toho, co chcete (≈ô√≠k√°, kdy slevu nedostanete).\n",
                "*   **V√Ωsledek:** Pokud po≈°lete LLM 10 takov√Ωch dokument≈Ø, zahlt√≠te ho balastem (tzv. \"lost in the middle\").\n",
                "\n",
                "### 2. ≈òe≈°en√≠: Contextual Compression (Re-ranking)\n",
                "P≈ôedstavte si to jako dvouf√°zov√Ω proces **r√Ω≈æov√°n√≠ zlata**:\n",
                "\n",
                "1.  **Bagr (Base Retriever):** Nejd≈ô√≠ve nabereme velkou l≈æ√≠ci hl√≠ny a kamen√≠. ≈òekneme datab√°zi: *\"Dej mi v≈°echno, co aspo≈à trochu souvis√≠ s dotazem.\"* (Nap≈ô. 20 dokument≈Ø).\n",
                "2.  **Pinzeta (Compressor/Nov√© LLM):** Pot√© vezmeme chytr√Ω model (LLM), kter√Ω si tƒõch 20 dokument≈Ø p≈ôeƒçte a ≈ôekne: *\"Tohle je jen o pl√°novan√© √∫dr≈æbƒõ - vyhodit. Tohle je o slev√°ch na rohl√≠ky - vyhodit. Tady! Tohle je o slev√°ch za v√Ωpadek - nechat.\"*\n",
                "\n",
                "Nav√≠c model dok√°≈æe text **\"vy≈æd√≠mat\"** (komprimovat). Pokud je dokument dlouh√Ω 500 slov, ale odpovƒõƒè je v jedn√© vƒõtƒõ, model v≈°echno ostatn√≠ sma≈æe a vr√°t√≠ v√°m jen tu jednu zlatou vƒõtu."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚ùì Dotaz: 'What is the SLA credit for 96% uptime?'\n",
                        "\n",
                        "‚úÖ Nalezeno relevantn√≠ch √∫ryvk≈Ø: 1\n",
                        "------------------------------\n",
                        "- < 99.0% but >= 95.0%: 25% Credit\n",
                        "------------------------------\n",
                        "(Zdroj: ../data/legal/sla_contract.txt)\n"
                    ]
                }
            ],
            "source": [
                "# Importy - sna≈æ√≠me se naƒç√≠st ze spr√°vn√©ho m√≠sta pro va≈°i verzi\n",
                "try:\n",
                "    from langchain.retrievers import ContextualCompressionRetriever\n",
                "    from langchain.retrievers.document_compressors import LLMChainExtractor\n",
                "except ImportError:\n",
                "    from langchain_classic.retrievers import ContextualCompressionRetriever\n",
                "    from langchain_classic.retrievers.document_compressors import LLMChainExtractor\n",
                "\n",
                "# 1. Vytvo≈ôen√≠ kompresoru\n",
                "# Tento \"inteligentn√≠ filtr\" pou≈æ√≠v√° LLM k posouzen√≠ ka≈æd√©ho dokumentu\n",
                "compressor = LLMChainExtractor.from_llm(llm)\n",
                "\n",
                "# 2. Sestaven√≠ Retrieveru\n",
                "# Spoj√≠me \"Bagr\" (vectorstore -- hled√° hrubƒõ) a \"Pinzetu\" (compressor -- ƒçist√≠)\n",
                "compression_retriever = ContextualCompressionRetriever(\n",
                "    base_compressor=compressor,\n",
                "    base_retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}) # Vyt√°hni z datab√°ze 5 nejlep≈°√≠ch polo≈æek, kter√© najde≈°. V kontextu RAG jsou tyto \"polo≈æky\" technicky vzato Chunky (ty rozsekan√© kousky textu, kter√© jsme vytvo≈ôili pomoc√≠ splitteru). Pro LangChain je to objekt Document, ale fakticky je to Chunk.\n",
                ")\n",
                "\n",
                "# 3. Testov√°n√≠\n",
                "query = \"What is the SLA credit for 96% uptime?\"\n",
                "print(f\"‚ùì Dotaz: '{query}'\\n\")\n",
                "\n",
                "# Zkus√≠me naj√≠t dokumenty\n",
                "compressed_docs = compression_retriever.invoke(query)\n",
                "\n",
                "print(f\"‚úÖ Nalezeno relevantn√≠ch √∫ryvk≈Ø: {len(compressed_docs)}\")\n",
                "if len(compressed_docs) > 0:\n",
                "    print(\"-\" * 30)\n",
                "    # V≈°imnƒõte si, ≈æe vr√°cen√Ω text je krat≈°√≠ ne≈æ origin√°l - je \"vyƒçi≈°tƒõn√Ω\"\n",
                "    print(compressed_docs[0].page_content)\n",
                "    print(\"-\" * 30)\n",
                "    print(f\"(Zdroj: {compressed_docs[0].metadata.get('source', 'nezn√°m√Ω')})\")\n",
                "else:\n",
                "    print(\"‚ùå Model vyhodnotil, ≈æe ≈æ√°dn√Ω dokument neobsahuje p≈ô√≠mou odpovƒõƒè.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "We have explored:\n",
                "- **MultiQuery**: For vague user intent.\n",
                "- **ParentDocument**: For better context management.\n",
                "- **Compression**: For precision filtering.\n",
                "\n",
                "In the next notebook, we will learn how to **evaluate** which of these is actually better for our use case using RAGAS."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
