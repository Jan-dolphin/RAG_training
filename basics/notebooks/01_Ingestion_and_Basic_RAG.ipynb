{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 1: Ingestion and Basic RAG\n",
                "\n",
                "Welcome to the **Deepnote RAG Training** series. In this first notebook, we will build the foundation of a Retrieval-Augmented Generation (RAG) system.\n",
                "\n",
                "## What is RAG?\n",
                "Large Language Models (LLMs) like GPT-4 are frozen in time. They don't know about your private data, your company's contracts, or the latest financial report from yesterday. **RAG** solves this by:\n",
                "1. **Retrieving** relevant documents based on your query.\n",
                "2. **Augmenting** the prompt with these documents.\n",
                "3. **Generating** an answer using the LLM + the context.\n",
                "\n",
                "## 1. Setup\n",
                "First, we load the environment variables (API Keys) and import necessary libraries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "c1596e33",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: langchain==1.1.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 1)) (1.1.3)\n",
                        "Requirement already satisfied: langchain-openai==1.1.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 2)) (1.1.1)\n",
                        "Requirement already satisfied: langchain-community==0.4.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 3)) (0.4.1)\n",
                        "Requirement already satisfied: chromadb==1.3.6 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 4)) (1.3.6)\n",
                        "Requirement already satisfied: faiss-cpu==1.13.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 5)) (1.13.1)\n",
                        "Requirement already satisfied: openai==2.9.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 6)) (2.9.0)\n",
                        "Requirement already satisfied: ragas==0.4.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 7)) (0.4.1)\n",
                        "Requirement already satisfied: tiktoken==0.12.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 8)) (0.12.0)\n",
                        "Requirement already satisfied: datasets==4.4.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 9)) (4.4.1)\n",
                        "Requirement already satisfied: pandas==2.2.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 10)) (2.2.3)\n",
                        "Requirement already satisfied: ipywidgets==8.1.8 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 11)) (8.1.8)\n",
                        "Requirement already satisfied: jupyter==1.1.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 12)) (1.1.1)\n",
                        "Requirement already satisfied: python-dotenv==1.2.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 13)) (1.2.1)\n",
                        "Requirement already satisfied: unstructured==0.18.21 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 14)) (0.18.21)\n",
                        "Requirement already satisfied: markdown==3.10 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r ../requirements.txt (line 15)) (3.10)\n",
                        "Requirement already satisfied: langchain-core<2.0.0,>=1.1.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain==1.1.3->-r ../requirements.txt (line 1)) (1.1.3)\n",
                        "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain==1.1.3->-r ../requirements.txt (line 1)) (1.0.4)\n",
                        "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain==1.1.3->-r ../requirements.txt (line 1)) (2.11.7)\n",
                        "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (1.0.0)\n",
                        "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (2.0.45)\n",
                        "Requirement already satisfied: requests<3.0.0,>=2.32.5 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (2.32.5)\n",
                        "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (6.0.3)\n",
                        "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (3.12.15)\n",
                        "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (9.1.2)\n",
                        "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (0.6.7)\n",
                        "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (2.12.0)\n",
                        "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (0.4.59)\n",
                        "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (0.4.0)\n",
                        "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-community==0.4.1->-r ../requirements.txt (line 3)) (2.2.5)\n",
                        "Requirement already satisfied: build>=1.0.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.3.0)\n",
                        "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.4.3)\n",
                        "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.34.0)\n",
                        "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (5.4.0)\n",
                        "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (4.12.2)\n",
                        "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.23.2)\n",
                        "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.39.1)\n",
                        "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.39.1)\n",
                        "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.39.1)\n",
                        "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.22.1)\n",
                        "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.48.9)\n",
                        "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (4.67.1)\n",
                        "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (7.7.0)\n",
                        "Requirement already satisfied: importlib-resources in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (6.5.2)\n",
                        "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.76.0)\n",
                        "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (5.0.0)\n",
                        "Requirement already satisfied: typer>=0.9.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.20.0)\n",
                        "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (34.1.0)\n",
                        "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (5.2.0)\n",
                        "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (3.11.5)\n",
                        "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.28.1)\n",
                        "Requirement already satisfied: rich>=10.11.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (14.2.0)\n",
                        "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb==1.3.6->-r ../requirements.txt (line 4)) (4.25.1)\n",
                        "Requirement already satisfied: packaging in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from faiss-cpu==1.13.1->-r ../requirements.txt (line 5)) (25.0)\n",
                        "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai==2.9.0->-r ../requirements.txt (line 6)) (4.9.0)\n",
                        "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai==2.9.0->-r ../requirements.txt (line 6)) (1.9.0)\n",
                        "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai==2.9.0->-r ../requirements.txt (line 6)) (0.11.1)\n",
                        "Requirement already satisfied: sniffio in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai==2.9.0->-r ../requirements.txt (line 6)) (1.3.1)\n",
                        "Requirement already satisfied: nest-asyncio in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ragas==0.4.1->-r ../requirements.txt (line 7)) (1.6.0)\n",
                        "Requirement already satisfied: appdirs in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.4.1->-r ../requirements.txt (line 7)) (1.4.4)\n",
                        "Requirement already satisfied: diskcache>=5.6.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.4.1->-r ../requirements.txt (line 7)) (5.6.3)\n",
                        "Requirement already satisfied: instructor in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.4.1->-r ../requirements.txt (line 7)) (1.13.0)\n",
                        "Requirement already satisfied: pillow>=10.4.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.4.1->-r ../requirements.txt (line 7)) (12.0.0)\n",
                        "Requirement already satisfied: networkx in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.4.1->-r ../requirements.txt (line 7)) (3.6.1)\n",
                        "Requirement already satisfied: scikit-network in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ragas==0.4.1->-r ../requirements.txt (line 7)) (0.33.5)\n",
                        "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken==0.12.0->-r ../requirements.txt (line 8)) (2025.11.3)\n",
                        "Requirement already satisfied: filelock in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==4.4.1->-r ../requirements.txt (line 9)) (3.20.0)\n",
                        "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==4.4.1->-r ../requirements.txt (line 9)) (22.0.0)\n",
                        "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==4.4.1->-r ../requirements.txt (line 9)) (0.4.0)\n",
                        "Requirement already satisfied: xxhash in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==4.4.1->-r ../requirements.txt (line 9)) (3.6.0)\n",
                        "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==4.4.1->-r ../requirements.txt (line 9)) (0.70.18)\n",
                        "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1->-r ../requirements.txt (line 9)) (2025.10.0)\n",
                        "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==4.4.1->-r ../requirements.txt (line 9)) (1.2.2)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas==2.2.3->-r ../requirements.txt (line 10)) (2.8.2)\n",
                        "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas==2.2.3->-r ../requirements.txt (line 10)) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas==2.2.3->-r ../requirements.txt (line 10)) (2025.2)\n",
                        "Requirement already satisfied: comm>=0.1.3 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (0.2.3)\n",
                        "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (9.8.0)\n",
                        "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (5.14.3)\n",
                        "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (4.0.15)\n",
                        "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (3.0.16)\n",
                        "Requirement already satisfied: notebook in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter==1.1.1->-r ../requirements.txt (line 12)) (7.5.0)\n",
                        "Requirement already satisfied: jupyter-console in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter==1.1.1->-r ../requirements.txt (line 12)) (6.6.3)\n",
                        "Requirement already satisfied: nbconvert in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter==1.1.1->-r ../requirements.txt (line 12)) (7.16.6)\n",
                        "Requirement already satisfied: ipykernel in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from jupyter==1.1.1->-r ../requirements.txt (line 12)) (7.1.0)\n",
                        "Requirement already satisfied: jupyterlab in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter==1.1.1->-r ../requirements.txt (line 12)) (4.5.0)\n",
                        "Requirement already satisfied: charset-normalizer in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (3.4.3)\n",
                        "Requirement already satisfied: filetype in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (1.2.0)\n",
                        "Requirement already satisfied: python-magic in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (0.4.27)\n",
                        "Requirement already satisfied: lxml in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (6.0.2)\n",
                        "Requirement already satisfied: nltk in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (3.9.2)\n",
                        "Requirement already satisfied: beautifulsoup4 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (4.13.4)\n",
                        "Requirement already satisfied: emoji in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (2.15.0)\n",
                        "Requirement already satisfied: python-iso639 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (2025.11.16)\n",
                        "Requirement already satisfied: langdetect in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (1.0.9)\n",
                        "Requirement already satisfied: rapidfuzz in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (3.14.3)\n",
                        "Requirement already satisfied: backoff in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (2.2.1)\n",
                        "Requirement already satisfied: unstructured-client in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (0.42.4)\n",
                        "Requirement already satisfied: wrapt in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (2.0.1)\n",
                        "Requirement already satisfied: psutil in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (7.1.3)\n",
                        "Requirement already satisfied: python-oxmsg in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (0.0.2)\n",
                        "Requirement already satisfied: html5lib in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured==0.18.21->-r ../requirements.txt (line 14)) (1.1)\n",
                        "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (2.6.1)\n",
                        "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (1.4.0)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (25.3.0)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (1.7.0)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (6.6.4)\n",
                        "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (0.3.2)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (1.20.1)\n",
                        "Requirement already satisfied: idna>=2.8 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai==2.9.0->-r ../requirements.txt (line 6)) (3.10)\n",
                        "Requirement already satisfied: pyproject_hooks in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from build>=1.0.3->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.2.0)\n",
                        "Requirement already satisfied: colorama in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from build>=1.0.3->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.4.6)\n",
                        "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (3.26.1)\n",
                        "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (0.9.0)\n",
                        "Requirement already satisfied: certifi in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (2025.1.31)\n",
                        "Requirement already satisfied: httpcore==1.* in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.0.9)\n",
                        "Requirement already satisfied: h11>=0.16 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.16.0)\n",
                        "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets==4.4.1->-r ../requirements.txt (line 9)) (1.2.0)\n",
                        "Requirement already satisfied: shellingham in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets==4.4.1->-r ../requirements.txt (line 9)) (1.5.4)\n",
                        "Requirement already satisfied: typer-slim in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets==4.4.1->-r ../requirements.txt (line 9)) (0.20.0)\n",
                        "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (5.2.1)\n",
                        "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (1.1.1)\n",
                        "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (0.19.2)\n",
                        "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (0.2.1)\n",
                        "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (3.0.52)\n",
                        "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (2.19.2)\n",
                        "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (0.6.3)\n",
                        "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (2025.4.1)\n",
                        "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.36.2)\n",
                        "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.27.1)\n",
                        "Requirement already satisfied: six>=1.9.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.17.0)\n",
                        "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (2.43.0)\n",
                        "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.9.0)\n",
                        "Requirement already satisfied: requests-oauthlib in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (2.0.0)\n",
                        "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (2.3.0)\n",
                        "Requirement already satisfied: durationpy>=0.7 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.10)\n",
                        "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (1.0.0)\n",
                        "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain==1.1.3->-r ../requirements.txt (line 1)) (1.33)\n",
                        "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain==1.1.3->-r ../requirements.txt (line 1)) (0.12.0)\n",
                        "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3->-r ../requirements.txt (line 1)) (3.0.1)\n",
                        "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3->-r ../requirements.txt (line 1)) (1.0.5)\n",
                        "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.3->-r ../requirements.txt (line 1)) (0.2.15)\n",
                        "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (1.0.0)\n",
                        "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (0.25.0)\n",
                        "Requirement already satisfied: coloredlogs in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==1.3.6->-r ../requirements.txt (line 4)) (15.0.1)\n",
                        "Requirement already satisfied: flatbuffers in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==1.3.6->-r ../requirements.txt (line 4)) (25.9.23)\n",
                        "Requirement already satisfied: protobuf in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==1.3.6->-r ../requirements.txt (line 4)) (6.33.2)\n",
                        "Requirement already satisfied: sympy in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.14.0)\n",
                        "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (8.7.0)\n",
                        "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.72.0)\n",
                        "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.39.1)\n",
                        "Requirement already satisfied: opentelemetry-proto==1.39.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.39.1)\n",
                        "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.60b1)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.1.3->-r ../requirements.txt (line 1)) (0.7.0)\n",
                        "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.1.3->-r ../requirements.txt (line 1)) (2.33.2)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.1.3->-r ../requirements.txt (line 1)) (0.4.1)\n",
                        "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (4.0.0)\n",
                        "Requirement already satisfied: greenlet>=1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (3.3.0)\n",
                        "Requirement already satisfied: click>=8.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer>=0.9.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (8.1.8)\n",
                        "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.7.1)\n",
                        "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.1.1)\n",
                        "Requirement already satisfied: websockets>=10.4 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.6->-r ../requirements.txt (line 4)) (15.0.1)\n",
                        "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->unstructured==0.18.21->-r ../requirements.txt (line 14)) (2.7)\n",
                        "Requirement already satisfied: webencodings in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from html5lib->unstructured==0.18.21->-r ../requirements.txt (line 14)) (0.5.1)\n",
                        "Requirement already satisfied: docstring-parser<1.0,>=0.16 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from instructor->ragas==0.4.1->-r ../requirements.txt (line 7)) (0.17.0)\n",
                        "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from instructor->ragas==0.4.1->-r ../requirements.txt (line 7)) (3.1.6)\n",
                        "Requirement already satisfied: pre-commit>=4.3.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from instructor->ragas==0.4.1->-r ../requirements.txt (line 7)) (4.5.0)\n",
                        "Requirement already satisfied: ty>=0.0.1a23 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from instructor->ragas==0.4.1->-r ../requirements.txt (line 7)) (0.0.1a33)\n",
                        "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipykernel->jupyter==1.1.1->-r ../requirements.txt (line 12)) (1.8.18)\n",
                        "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipykernel->jupyter==1.1.1->-r ../requirements.txt (line 12)) (8.7.0)\n",
                        "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipykernel->jupyter==1.1.1->-r ../requirements.txt (line 12)) (5.9.1)\n",
                        "Requirement already satisfied: pyzmq>=25 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipykernel->jupyter==1.1.1->-r ../requirements.txt (line 12)) (27.1.0)\n",
                        "Requirement already satisfied: tornado>=6.2 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from ipykernel->jupyter==1.1.1->-r ../requirements.txt (line 12)) (6.5.3)\n",
                        "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (2.0.5)\n",
                        "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (2.3.0)\n",
                        "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (2.17.0)\n",
                        "Requirement already satisfied: jupyterlab-server<3,>=2.28.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (2.28.0)\n",
                        "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.2.4)\n",
                        "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (80.9.0)\n",
                        "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (6.3.0)\n",
                        "Requirement already satisfied: defusedxml in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.7.1)\n",
                        "Requirement already satisfied: jupyterlab-pygments in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.3.0)\n",
                        "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (3.0.2)\n",
                        "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (3.1.4)\n",
                        "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.10.2)\n",
                        "Requirement already satisfied: nbformat>=5.7 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (5.10.4)\n",
                        "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (1.5.1)\n",
                        "Requirement already satisfied: joblib in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk->unstructured==0.18.21->-r ../requirements.txt (line 14)) (1.4.2)\n",
                        "Requirement already satisfied: olefile in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-oxmsg->unstructured==0.18.21->-r ../requirements.txt (line 14)) (0.47)\n",
                        "Requirement already satisfied: scipy>=1.7.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-network->ragas==0.4.1->-r ../requirements.txt (line 7)) (1.15.2)\n",
                        "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured-client->unstructured==0.18.21->-r ../requirements.txt (line 14)) (25.1.0)\n",
                        "Requirement already satisfied: cryptography>=3.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured-client->unstructured==0.18.21->-r ../requirements.txt (line 14)) (44.0.3)\n",
                        "Requirement already satisfied: pypdf>=6.2.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unstructured-client->unstructured==0.18.21->-r ../requirements.txt (line 14)) (6.4.1)\n",
                        "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (1.4.0)\n",
                        "Requirement already satisfied: cffi>=1.12 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured==0.18.21->-r ../requirements.txt (line 14)) (2.0.0)\n",
                        "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (6.2.2)\n",
                        "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.4.2)\n",
                        "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (4.9.1)\n",
                        "Requirement already satisfied: zipp>=3.20 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (3.23.0)\n",
                        "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (0.8.5)\n",
                        "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain==1.1.3->-r ../requirements.txt (line 1)) (3.0.0)\n",
                        "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.1.1->-r ../requirements.txt (line 12)) (4.5.1)\n",
                        "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (25.1.0)\n",
                        "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.12.0)\n",
                        "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.5.3)\n",
                        "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.23.1)\n",
                        "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (3.0.2)\n",
                        "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (1.8.3)\n",
                        "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.18.1)\n",
                        "Requirement already satisfied: babel>=2.10 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (2.17.0)\n",
                        "Requirement already satisfied: json5>=0.9.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.12.1)\n",
                        "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.3->-r ../requirements.txt (line 1)) (1.12.0)\n",
                        "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.1.2)\n",
                        "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter==1.1.1->-r ../requirements.txt (line 12)) (2.21.2)\n",
                        "Requirement already satisfied: cfgv>=2.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pre-commit>=4.3.0->instructor->ragas==0.4.1->-r ../requirements.txt (line 7)) (3.5.0)\n",
                        "Requirement already satisfied: identify>=1.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pre-commit>=4.3.0->instructor->ragas==0.4.1->-r ../requirements.txt (line 7)) (2.6.15)\n",
                        "Requirement already satisfied: nodeenv>=0.11.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pre-commit>=4.3.0->instructor->ragas==0.4.1->-r ../requirements.txt (line 7)) (1.9.1)\n",
                        "Requirement already satisfied: virtualenv>=20.10.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pre-commit>=4.3.0->instructor->ragas==0.4.1->-r ../requirements.txt (line 7)) (20.35.4)\n",
                        "Requirement already satisfied: wcwidth in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (0.2.14)\n",
                        "Requirement already satisfied: executing>=1.2.0 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (2.2.1)\n",
                        "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (3.0.1)\n",
                        "Requirement already satisfied: pure-eval in c:\\users\\jan.petr\\appdata\\roaming\\python\\python313\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets==8.1.8->-r ../requirements.txt (line 11)) (0.2.3)\n",
                        "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1->-r ../requirements.txt (line 3)) (1.1.0)\n",
                        "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==1.3.6->-r ../requirements.txt (line 4)) (10.0)\n",
                        "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (3.3.1)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==1.3.6->-r ../requirements.txt (line 4)) (1.3.0)\n",
                        "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (25.1.0)\n",
                        "Requirement already satisfied: pycparser in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured==0.18.21->-r ../requirements.txt (line 14)) (2.23)\n",
                        "Requirement already satisfied: pyreadline3 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==1.3.6->-r ../requirements.txt (line 4)) (3.5.4)\n",
                        "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (4.0.0)\n",
                        "Requirement already satisfied: rfc3339-validator in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.1.4)\n",
                        "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (0.1.1)\n",
                        "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.3.6->-r ../requirements.txt (line 4)) (0.6.1)\n",
                        "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas==0.4.1->-r ../requirements.txt (line 7)) (0.4.0)\n",
                        "Requirement already satisfied: fqdn in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (1.5.1)\n",
                        "Requirement already satisfied: isoduration in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (20.11.0)\n",
                        "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (1.1.0)\n",
                        "Requirement already satisfied: uri-template in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (1.3.0)\n",
                        "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (25.10.0)\n",
                        "Requirement already satisfied: lark>=1.2.2 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (1.3.1)\n",
                        "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\jan.petr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter==1.1.1->-r ../requirements.txt (line 12)) (1.4.0)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
                        "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%pip install -r ../requirements.txt\n",
                "import os\n",
                "import openai\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "# If using Deepnote's integration, the key is already in env\n",
                "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "73032ea7",
            "metadata": {},
            "source": [
                "## 2. Document Loading\n",
                "**Concept:** Your data exists in many formats (PDF, Markdown, CSV, JSON). we need to standardise it into a `Document` object (text + metadata).\n",
                "\n",
                "We will load the synthetic data we created in the `data/` folder."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c7c037c7",
            "metadata": {},
            "source": [
                "###  Poznmky k natn dat (Data Ingestion)\n",
                "\n",
                "Tento krok slou k **normalizaci dat**. Nezle na tom, zda je zdrojovm souborem [.txt](cci:7://file:///c:/Users/jan.petr/OneDrive%20-%20dolphinconsulting.cz/Projects/rag-training/data/legal/sla_contract.txt:0:0-0:0), [.csv](cci:7://file:///c:/Users/jan.petr/OneDrive%20-%20dolphinconsulting.cz/Projects/rag-training/data/finance/financial_report.csv:0:0-0:0) nebo [.md](cci:7://file:///c:/Users/jan.petr/OneDrive%20-%20dolphinconsulting.cz/Projects/rag-training/data/tech_docs/api_docs.md:0:0-0:0)  nam clem je pevst ve na jednotn objekt **Dokument**, se kterm um RAG systm pracovat.\n",
                "\n",
                "#### 1. Co je to `Document` objekt?\n",
                "Kad naten kus dat je v LangChainu reprezentovn objektem, kter m dv hlavn sti:\n",
                "* **`page_content`**: Samotn text (obsah).\n",
                "* **`metadata`**: Informace o pvodu (nap. `{source: \"cesta/k/souboru.txt\", row: 5}`).\n",
                "\n",
                "#### 2. Jak funguj jednotliv Loadery?\n",
                "Loadery se staraj o pevod surovch dat na text.\n",
                "* **`TextLoader`**: \"Hloup\" loader. Vezme cel obsah souboru tak, jak je, a vlo ho do jednoho dokumentu.\n",
                "* **`CSVLoader`**: \"Chytr\" loader. Kad dek tabulky pevede na **samostatn dokument**. Data zformtuje do dvojic `Sloupec: Hodnota`, aby si LLM zachovalo kontext (v, co kter slo znamen).\n",
                "* **`UnstructuredMarkdownLoader`**: Sna se parsovat strukturu. asto odstrauje formtovac znaky (jako `**` pro tun psmo), aby zbyl ist kontextuln text.\n",
                "\n",
                "#### 3. Co se dje se znaky? (Encoding & Normalizace)\n",
                "* **Kdovn**: Systm oekv standardn **UTF-8**. Pokud jsou v souboru esk znaky uloen v jinm kdovn (nap. Windows-1250), loader me selhat nebo zobrazit nesmysly.\n",
                "* **Opravy chyb**: Loadery **nefunguj** jako spell-checker. Pokud je ve zdrojovm textu peklep, bude i v natenm dokumentu.\n",
                "* **Formtovn**: Bl znaky (mezery, konce dk) jsou asto sjednoceny (normalizovny), aby byl text kompaktnj."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "307d4de6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 1 text docs, 1 md docs, 4 csv rows.\n"
                    ]
                }
            ],
            "source": [
                "from langchain_community.document_loaders import TextLoader, JSONLoader, CSVLoader, UnstructuredMarkdownLoader\n",
                "\n",
                "ts_path = \"../data/legal/sla_contract.txt\"\n",
                "md_path = \"../data/tech_docs/api_docs.md\"\n",
                "csv_path = \"../data/finance/financial_report.csv\"\n",
                "\n",
                "# 1. Text Loader\n",
                "text_loader = TextLoader(ts_path)\n",
                "documents_text = text_loader.load()\n",
                "\n",
                "# 2. Markdown Loader\n",
                "md_loader = UnstructuredMarkdownLoader(md_path)\n",
                "documents_md = md_loader.load()\n",
                "\n",
                "# 3. CSV Loader\n",
                "csv_loader = CSVLoader(csv_path)\n",
                "documents_csv = csv_loader.load()\n",
                "\n",
                "print(f\"Loaded {len(documents_text)} text docs, {len(documents_md)} md docs, {len(documents_csv)} csv rows.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "cf5555c7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- TEXT DOCUMENT ---\n",
                        "SERVICE LEVEL AGREEMENT (SLA) for NebulaDB Enterprise\n",
                        "\n",
                        "1. DEFINITIONS\n",
                        "\"Uptime\" refers to the availability of the Service during a billing month.\n",
                        "\"Downtime\" refers to a period of time exceeding 5 minutes where the Error Rate is greater than 5%.\n",
                        "\n",
                        "2. SERVICE COMMITMENT\n",
                        "NebulaDB commits to a Monthly Uptime Percentage of at least 99.99% (\"Service Commitment\").\n",
                        "\n",
                        "3. SERVICE CREDITS\n",
                        "If we do not meet the Service Commitment, you will be eligible to receive a Service Credit as follows:\n",
                        "- < 99.99% but >= 99.0%: 10% Credit\n",
                        "- < 99.0% but >= 95.0%: 25% Credit\n",
                        "- < 95.0%: 100% Credit\n",
                        "\n",
                        "4. EXCLUSIONS\n",
                        "The Service Commitment does not apply to any unavailability, suspension, or termination of NebulaDB performance issues: (i) caused by factors outside of our reasonable control, including any force majeure event or Internet access or related problems beyond the demarcation point of NebulaDB.\n",
                        "\n",
                        "5. CLAIMS\n",
                        "To receive a Service Credit, you must submit a claim by opening a case in the NebulaDB Support Center within 30 days of the incident.\n",
                        "\n",
                        "Metadata: {'source': '../data/legal/sla_contract.txt'}\n",
                        "\n",
                        "--- MARKDOWN DOCUMENT ---\n",
                        "NebulaDB API Documentation\n",
                        "\n",
                        "Introduction\n",
                        "\n",
                        "NebulaDB is a high-performance distributed key-value store designed for interstellar latency.\n",
                        "\n",
                        "Authentication\n",
                        "\n",
                        "All requests must include the X-Nebula-Token header.\n",
                        "\n",
                        "curl -H \"X-Nebula-Token: <your_token>\" https://api.nebuladb.com/v1/stats\n",
                        "\n",
                        "Endpoints\n",
                        "\n",
                        "GET /v1/clusters\n",
                        "\n",
                        "Retrieves a list of all active clusters.\n",
                        "\n",
                        "Parameters: - region (optional): Filter by region code (e.g., us-east-1, mars-north-2).\n",
                        "\n",
                        "Response:\n",
                        "\n",
                        "{\n",
                        "  \"clusters\": [\n",
                        "    {\"id\": \"c-123\", \"status\": \n",
                        "\n",
                        "--- CSV ROW 1 ---\n",
                        "Quarter: Q1 2024\n",
                        "Revenue: 1000000\n",
                        "Expenses: 800000\n",
                        "Profit: 200000\n",
                        "Notes: Strong growth in Mars region.\n",
                        "Metadata: {'source': '../data/finance/financial_report.csv', 'row': 0}\n"
                    ]
                }
            ],
            "source": [
                "# 1. Zobrazen obsahu textovho dokumentu\n",
                "print(\"--- TEXT DOCUMENT ---\")\n",
                "print(documents_text[0].page_content)\n",
                "print(\"Metadata:\", documents_text[0].metadata)\n",
                "\n",
                "# 2. Zobrazen obsahu Markdown dokumentu\n",
                "print(\"\\n--- MARKDOWN DOCUMENT ---\")\n",
                "# Zobrazme teba jen prvnch 500 znak, pokud je to dlouh\n",
                "print(documents_md[0].page_content[:500]) \n",
                "\n",
                "# 3. Zobrazen CSV (kad dek je obvykle jeden dokument)\n",
                "print(\"\\n--- CSV ROW 1 ---\")\n",
                "print(documents_csv[0].page_content)\n",
                "print(\"Metadata:\", documents_csv[0].metadata)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Chunking (Text Splitting)\n",
                "\n",
                "**Concept:** LLMs have context windows. We can't stuff a 100-page contract into one prompt. Also, retrieving smaller, specific chunks is more accurate than retrieving whole documents.\n",
                "\n",
                "**Technique:**\n",
                "- `CharacterTextSplitter`: Simple, splits by character count.\n",
                "- `RecursiveCharacterTextSplitter`: Smarter, tries to keep paragraphs and sentences together."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9abdfcc1",
            "metadata": {},
            "source": [
                "#  Detailn vysvtlen parametr `RecursiveCharacterTextSplitter`\n",
                "\n",
                "## 1. Zsadn parametry (Ovlivuj kvalitu RAG)\n",
                "\n",
                "### `chunk_size` (int)\n",
                "*   **Default:** `4000`\n",
                "*   **Co to je:** Maximln clov velikost jednoho kousku textu (chunku).\n",
                "*   **Vliv:** Pokud je pli velk, LLM se zahlt balastem. Pokud pli mal, ztratte kontext.\n",
                "*   **Doporuen:** Pro GPT-4 a RAG se obvykle nastavuje na **500 a 1000**.\n",
                "\n",
                "### `chunk_overlap` (int)\n",
                "*   **Default:** `200`\n",
                "*   **Co to je:** Poet znak, kter se pekrvaj mezi koncem jednoho a zatkem druhho chunku.\n",
                "*   **Vliv:** Zabrauje tomu, aby dleit informace (nap. vta) byla \"rozznuta\" v plce a ztratila smysl.\n",
                "*   **Doporuen:** Obvykle **1020 %** velikosti `chunk_size`.\n",
                "\n",
                "### `separators` (list[str] | None)\n",
                "*   **Default:** `None` (Intern: `[\"\\n\\n\", \"\\n\", \" \", \"\"]`)\n",
                "*   **Co to je:** Seznam oddlova seazen podle priority (od nejsilnjho po nejslab).\n",
                "*   **Vliv:** Uruje strategii dlen. Splitter zkou dlit podle 1. oddlovae (odstavce). Pokud je chunk stle moc velk, zkus 2. oddlova (dky), pak 3. (slova) atd.\n",
                "*   **Kdy mnit:** Pokud dlte kd (pouijte `RecursiveCharacterTextSplitter.from_language`) nebo specifick data.\n",
                "\n",
                "---\n",
                "\n",
                "## 2. Parametry chovn oddlova\n",
                "\n",
                "### `keep_separator` (bool | \"start\" | \"end\")\n",
                "*   **Default:** `True`\n",
                "*   **Co to je:** Uruje, co se stane se znakem, podle kterho se dlilo (nap. `\\n\\n`).\n",
                "    *   `True` (nebo `\"end\"`): Oddlova zstane na **konci** pedchozho chunku.\n",
                "    *   `\"start\"`: Oddlova se pesune na **zatek** nsledujcho chunku.\n",
                "    *   `False`: Oddlova se pln vymae.\n",
                "*   **Vliv:** Zachovn (`True`) pomh LLM pochopit strukturu textu (e tam byl konec odstavce).\n",
                "\n",
                "### `is_separator_regex` (bool)\n",
                "*   **Default:** `False`\n",
                "*   **Co to je:** Pokud `True`, chpe poloky v `separators` jako regulrn vrazy (RegEx) msto obyejnho textu.\n",
                "*   **Vliv:** Umouje sloitj pravidla dlen (nap. \"rozdl v mst, kde je teka nsledovan velkm psmenem\").\n",
                "\n",
                "### `strip_whitespace` (bool)\n",
                "*   **Default:** `True`\n",
                "*   **Co to je:** Pokud `True`, odstran nadbyten mezery a przdn znaky na plnm zatku a konci hotovho chunku.\n",
                "*   **Vliv:** ist data, aby chunks nezanaly zbytenmi entery nebo mezerami.\n",
                "\n",
                "---\n",
                "\n",
                "## 3. Technick a mapovac parametry\n",
                "\n",
                "### `length_function` (Callable)\n",
                "*   **Default:** `len` (standardn funkce Pythonu pro poet znak)\n",
                "*   **Co to je:** Metr, kterm splitter m dlku textu. Uruje, co vlastn znamen slo v `chunk_size`.\n",
                "*   **Jak to funguje:**\n",
                "    *   **Znaky (Default):** Pokud parametr nezmnte, splitter pouv funkci `len()`. Nastaven `chunk_size=500` pak znamen **maximln 500 znak** (psmen, mezer, interpunkce). Je to rychl, ale pro LLM mn pesn (model \"nevid\" znaky, ale tokeny).\n",
                "    *   **Tokeny (Pokroil):** Pro RAG je asto lep mit pmo v jednotkch, kterm rozum model (tokeny). Nastaven `chunk_size=500` pak znamen **maximln 500 token**. To zajist, e efektivnji vyuijete kontextov okno modelu.\n",
                "*   **Pklad nastaven na tokeny:**\n",
                "    Pokud chcete dlit podle token (nap. pro modely OpenAI), muste pout knihovnu `tiktoken`:\n",
                "\n",
                "    ```python\n",
                "    import tiktoken\n",
                "\n",
                "    # Vytvome funkci, kter pot tokeny msto znak\n",
                "    def tiktoken_len(text):\n",
                "        tokenizer = tiktoken.get_encoding(\"cl100k_base\") # encoding pro GPT-3.5/4\n",
                "        tokens = tokenizer.encode(text)\n",
                "        return len(tokens)\n",
                "\n",
                "    # Pedme tuto funkci splitteru\n",
                "    splitter = RecursiveCharacterTextSplitter(\n",
                "        chunk_size=500,  # Nyn to znamen 500 TOKEN\n",
                "        chunk_overlap=50,\n",
                "        length_function=tiktoken_len\n",
                "    )\n",
                "    ```\n",
                "### `add_start_index` (bool)\n",
                "*   **Default:** `False`\n",
                "*   **Co to je:** Pokud `True`, pid do metadat chunku kl `start_index` s slem, na kterm znaku v pvodnm souboru tento chunk zan.\n",
                "*   **Vliv:** Uiten pro zvrazovn (highlighting) nalezenho textu v pvodnm dokumentu v UI aplikace."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "89c65bfb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Split 6 documents into 9 chunks.\n",
                        "Example chunk: SERVICE LEVEL AGREEMENT (SLA) for NebulaDB Enterprise\n",
                        "\n",
                        "1. DEFINITIONS\n",
                        "\"Uptime\" refers to the availability of the Service during a billing month.\n",
                        "\"Downtime\" refers to a period of time exceeding 5 minutes where the Error Rate is greater than 5%.\n",
                        "\n",
                        "2. SERVICE COMMITMENT\n",
                        "NebulaDB commits to a Monthly Uptime Percentage of at least 99.99% (\"Service Commitment\").\n"
                    ]
                }
            ],
            "source": [
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "splitter = RecursiveCharacterTextSplitter(\n",
                "    chunk_size=500,\n",
                "    chunk_overlap=50\n",
                ")\n",
                "all_docs = documents_text + documents_md + documents_csv\n",
                "chunks = splitter.split_documents(all_docs)\n",
                "print(f\"Split {len(all_docs)} documents into {len(chunks)} chunks.\")\n",
                "if len(chunks) > 0:\n",
                "    print(\"Example chunk:\", chunks[0].page_content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "72e43ed6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Pvodn dokumenty (all_docs): 6 ks\n",
                        "   - Typ objektu: <class 'langchain_core.documents.base.Document'>\n",
                        "   - Ukzka 1. dokumentu (znak: 1027):\n",
                        "     'SERVICE LEVEL AGREEMENT (SLA) for NebulaDB Enterprise\n",
                        "\n",
                        "1. DEFINITIONS\n",
                        "\"Uptime\" refers to the availab...'\n",
                        "     Metadata: {'source': '../data/legal/sla_contract.txt'}\n",
                        "\n",
                        "========================================\n",
                        "\n",
                        " Rozsekan sti (chunks): 9 ks\n",
                        "   - Typ objektu: <class 'langchain_core.documents.base.Document'> (Stle je to Document!)\n",
                        "   - Pvodn soubor '../data/legal/sla_contract.txt' byl rozdlen na 3 st.\n",
                        "   - Ukzka 1. chunku:\n",
                        "     'SERVICE LEVEL AGREEMENT (SLA) for NebulaDB Enterprise\n",
                        "\n",
                        "1. DEFINITIONS\n",
                        "\"Uptime\" refers to the availability of the Service during a billing month.\n",
                        "\"Downtime\" refers to a period of time exceeding 5 minutes where the Error Rate is greater than 5%.\n",
                        "\n",
                        "2. SERVICE COMMITMENT\n",
                        "NebulaDB commits to a Monthly Uptime Percentage of at least 99.99% (\"Service Commitment\").'\n",
                        "     Metadata chunku: {'source': '../data/legal/sla_contract.txt'}\n"
                    ]
                }
            ],
            "source": [
                "# --- INSPEKCE PROMNNCH (VARIABLE INSPECTION) ---\n",
                "\n",
                "# 1. Analza `all_docs` (Vechny dokumenty ped rozdlenm)\n",
                "# Co to je: Seznam vech dokument natench loadery. Kad dokument je objekt 'Document'.\n",
                "print(f\" Pvodn dokumenty (all_docs): {len(all_docs)} ks\")\n",
                "try:\n",
                "    print(\"   - Typ objektu:\", type(all_docs[0]))\n",
                "    # Zobrazme detail prvnho dokumentu (nap. SLA kontrakt)\n",
                "    if len(all_docs) > 0:\n",
                "        print(f\"   - Ukzka 1. dokumentu (znak: {len(all_docs[0].page_content)}):\")\n",
                "        print(f\"     '{all_docs[0].page_content[:100]}...'\") # Jen prvnch 100 znak\n",
                "        print(f\"     Metadata: {all_docs[0].metadata}\")\n",
                "except Exception as e:\n",
                "    print(f\"   - Chyba pi zobrazovn all_docs: {e}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
                "\n",
                "# 2. Analza `chunks` (Rozsekan kousky)\n",
                "# Co to je: Seznam dokument PO rozdlen splitterem.\n",
                "# Pro: Protoe pvodn dokumenty mohou bt pro LLM pli dlouh a nevely by se do kontextu.\n",
                "print(f\" Rozsekan sti (chunks): {len(chunks)} ks\")\n",
                "try:\n",
                "    if len(chunks) > 0:\n",
                "        print(\"   - Typ objektu:\", type(chunks[0]), \"(Stle je to Document!)\")\n",
                "\n",
                "        # Porovnn: Kolik chunk vzniklo z prvnho dokumentu?\n",
                "        # Filtrujeme chunky, kter maj stejn 'source' jako prvn dokument\n",
                "        if len(all_docs) > 0:\n",
                "            source_file = all_docs[0].metadata.get('source')\n",
                "            matching_chunks = [c for c in chunks if c.metadata.get('source') == source_file]\n",
                "\n",
                "            print(f\"   - Pvodn soubor '{source_file}' byl rozdlen na {len(matching_chunks)} st.\")\n",
                "            if len(matching_chunks) > 0:\n",
                "                print(\"   - Ukzka 1. chunku:\")\n",
                "                print(f\"     '{matching_chunks[0].page_content}'\")\n",
                "                print(f\"     Metadata chunku: {matching_chunks[0].metadata}\")\n",
                "except Exception as e:\n",
                "    print(f\"   - Chyba pi zobrazovn chunks: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "1071d70e",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[Document(metadata={'source': '../data/legal/sla_contract.txt'}, page_content='SERVICE LEVEL AGREEMENT (SLA) for NebulaDB Enterprise\\n\\n1. DEFINITIONS\\n\"Uptime\" refers to the availability of the Service during a billing month.\\n\"Downtime\" refers to a period of time exceeding 5 minutes where the Error Rate is greater than 5%.\\n\\n2. SERVICE COMMITMENT\\nNebulaDB commits to a Monthly Uptime Percentage of at least 99.99% (\"Service Commitment\").\\n\\n3. SERVICE CREDITS\\nIf we do not meet the Service Commitment, you will be eligible to receive a Service Credit as follows:\\n- < 99.99% but >= 99.0%: 10% Credit\\n- < 99.0% but >= 95.0%: 25% Credit\\n- < 95.0%: 100% Credit\\n\\n4. EXCLUSIONS\\nThe Service Commitment does not apply to any unavailability, suspension, or termination of NebulaDB performance issues: (i) caused by factors outside of our reasonable control, including any force majeure event or Internet access or related problems beyond the demarcation point of NebulaDB.\\n\\n5. CLAIMS\\nTo receive a Service Credit, you must submit a claim by opening a case in the NebulaDB Support Center within 30 days of the incident.\\n'),\n",
                            " Document(metadata={'source': '../data/tech_docs/api_docs.md'}, page_content='NebulaDB API Documentation\\n\\nIntroduction\\n\\nNebulaDB is a high-performance distributed key-value store designed for interstellar latency.\\n\\nAuthentication\\n\\nAll requests must include the X-Nebula-Token header.\\n\\ncurl -H \"X-Nebula-Token: <your_token>\" https://api.nebuladb.com/v1/stats\\n\\nEndpoints\\n\\nGET /v1/clusters\\n\\nRetrieves a list of all active clusters.\\n\\nParameters: - region (optional): Filter by region code (e.g., us-east-1, mars-north-2).\\n\\nResponse:\\n\\n{\\n  \"clusters\": [\\n    {\"id\": \"c-123\", \"status\": \"active\", \"region\": \"us-east-1\"},\\n    {\"id\": \"c-456\", \"status\": \"provisioning\", \"region\": \"mars-north-2\"}\\n  ]\\n}\\n\\nPOST /v1/clusters\\n\\nCreates a new cluster.\\n\\nBody: - name (required): Name of the cluster. - node_count (required): Number of nodes (min: 3, max: 100).\\n\\nError Codes\\n\\n400: Invalid parameters (e.g., node_count < 3).\\n\\n401: unauthorized.\\n\\n429: Rate limit exceeded (100 req/sec per token).'),\n",
                            " Document(metadata={'source': '../data/finance/financial_report.csv', 'row': 0}, page_content='Quarter: Q1 2024\\nRevenue: 1000000\\nExpenses: 800000\\nProfit: 200000\\nNotes: Strong growth in Mars region.'),\n",
                            " Document(metadata={'source': '../data/finance/financial_report.csv', 'row': 1}, page_content='Quarter: Q2 2024\\nRevenue: 1200000\\nExpenses: 850000\\nProfit: 350000\\nNotes: cost optimization in server fleets.'),\n",
                            " Document(metadata={'source': '../data/finance/financial_report.csv', 'row': 2}, page_content='Quarter: Q3 2024\\nRevenue: 1100000\\nExpenses: 900000\\nProfit: 200000\\nNotes: Seasonal dip expected.'),\n",
                            " Document(metadata={'source': '../data/finance/financial_report.csv', 'row': 3}, page_content='Quarter: Q4 2023\\nRevenue: 950000\\nExpenses: 750000\\nProfit: 200000\\nNotes: Previous year comparison.')]"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "all_docs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Vector Stores & Embeddings\n",
                "\n",
                "**Concept:** Computers don't understand text meaning, they understand numbers. **Embeddings** convert text into a vector (a list of numbers) where similar meanings are close together in space.\n",
                "\n",
                "We store these vectors in a **Vector Store** (like ChromaDB) to perform semantic search."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2b0a7f21",
            "metadata": {},
            "source": [
                "#  Co se dje v sti \"Embeddings & Vector Store\"?\n",
                "\n",
                "V tto fzi mnme **lidskou e** na **e strojovou**, abychom v n mohli efektivn vyhledvat.\n",
                "\n",
                "## 1. Embedding Model (Peklada)\n",
                "*   **Co to je:** Sluba (v naem ppad `text-embedding-ada-002` na Azure), kter vezme jakkoli text a vrt dlouh seznam sel (vektor).\n",
                "*   **Jak to funguje:** Model chpe vznamy slov. Slova s podobnm vznamem (nap. *krl* a *csa*) budou mt sla velmi blzko sebe.\n",
                "*   **Vsledek:** Kad n \"chunk\" textu se promn na seznam 1536 sel.\n",
                "\n",
                "## 2. Vector Store (Databze vznam)\n",
                "*   **Co to je:** Specializovan databze (zde `ChromaDB`), kter neum jen ukldat text, ale hlavn ty seln vektory.\n",
                "*   **Pro to potebujeme:** Klasick databze hled pesnou shodu (*obsahuje slovo \"smlouva\"?*). Vektorov databze hled **vznamovou blzkost** (*je tento dotaz podobn obsahu smlouvy?*).\n",
                "*   **Proces:**\n",
                "    1.  Vezmeme vechny `chunks`.\n",
                "    2.  Poleme je do Azure na \"peloen\" (embed).\n",
                "    3.  Vrt se nm vektory.\n",
                "    4.  Ulome je do `vectorstore` spolu s pvodnm textem a metadaty."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Smazna star databze: ../chroma_db\n",
                        " Nov VectorStore vytvoen a uloen do: ../chroma_db\n",
                        "VectorStore created with Azure OpenAI!\n"
                    ]
                }
            ],
            "source": [
                "from langchain_openai import AzureOpenAIEmbeddings\n",
                "from langchain_community.vectorstores import Chroma\n",
                "import os, shutil\n",
                "\n",
                "# POKUD MTE .ENV SOUBOR, HODNOTY SE NATOU Z NJ.\n",
                "# JINAK JE DOPLTE PMO DO UVOZOVEK:\n",
                "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"https://VAS_RESOURCE_NAME.openai.azure.com/\")\n",
                "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"VAS_API_KEY\") # V prosted asto jako AZURE_OPENAI_API_KEY\n",
                "deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\") # Nzev nasazen modelu (ne modelu samotnho!)\n",
                "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\") \n",
                "\n",
                "# Inicializace Azure Embeddings\n",
                "embeddings = AzureOpenAIEmbeddings(\n",
                "    azure_endpoint=azure_endpoint,\n",
                "    api_key=api_key,\n",
                "    azure_deployment=deployment_name,\n",
                "    openai_api_version=api_version,\n",
                ")\n",
                "\n",
                "\n",
                "import stat  # Poteba importovat\n",
                "\n",
                "# Tahle pomocn funkce \"odpoj\" read-only zmek, pokud na nj naraz\n",
                "def force_remove_readonly(func, path, exc_info):\n",
                "    os.chmod(path, stat.S_IWRITE) # Zmnme prva na zpis\n",
                "    func(path) # Zkusme operaci smazn znovu\n",
                "\n",
                "persist_directory = \"../chroma_db\"\n",
                "if os.path.exists(persist_directory):\n",
                "    # Pidme parametr onerror, kter zavol nai funkci pi chyb\n",
                "    shutil.rmtree(persist_directory, onerror=force_remove_readonly)\n",
                "    print(f\" Smazna star databze: {persist_directory}\")\n",
                "\n",
                "# 2. Vytvoen nov databze s persistenc\n",
                "# Nyn vytvome novou databzi a rovnou ji ulome na disk.\n",
                "vectorstore = Chroma.from_documents(\n",
                "    documents=chunks,\n",
                "    embedding=embeddings,\n",
                "    collection_name=\"rag_training_v1\",\n",
                "    persist_directory=persist_directory\n",
                ")\n",
                "print(f\" Nov VectorStore vytvoen a uloen do: {persist_directory}\")\n",
                "\n",
                "print(\"VectorStore created with Azure OpenAI!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3698f4e9",
            "metadata": {},
            "source": [
                "#  Jak funguj Embeddings a Vector Store? (Vysvtlen pro lidi)\n",
                "\n",
                "Pedstavte si cel proces jako **vztah mezi Kuchakou (Vector Store) a Chuovmi bukami (Embedding Model)**. Zde je vysvtlen krok za krokem.\n",
                "\n",
                "## 1. Co je to vlastn \"Embedding\"?\n",
                "**Embedding je peklada z lidtiny do \"seln ei\", kter rozum pota.**\n",
                "\n",
                "Pedstavte si, e mte mapu svta.\n",
                "*   Kdy eknu **\"Pes\"**, embedding model pevede toto slovo na pesn souadnice: `[50.123, 14.456]`.\n",
                "*   Kdy eknu **\"Koka\"**, model ekne: `[50.125, 14.458]` (le to na map kousek vedle psa).\n",
                "*   Kdy eknu **\"Vesmrn raketa\"**, model ekne: `[-20.000, 80.555]` (pln jin svtadl).\n",
                "\n",
                "To dlouh pole sel (v kdu promnn `vector`), kter vidte ve vstupu, jsou pesn tyto \"GPS souadnice vznamu\" v obrovskm, 1536-rozmrnm prostoru.\n",
                "\n",
                "---\n",
                "\n",
                "## 2. Mus mt embedding \"trval charakter\"?\n",
                "**Rozhodn ANO. To je naprosto klov.**\n",
                "\n",
                "Muste vdy pouvat **ten sam model** (stejn kl k map). Pedstavte si dva rzn modely jako dv rzn mapy:\n",
                "1.  **Model A (OpenAI):** Mapa Prahy.\n",
                "2.  **Model B (HuggingFace):** Mapa New Yorku.\n",
                "\n",
                "Pokud byste dokumenty uloili pomoc **Modelu A** (souadnice v Praze) a pak se ptali pomoc **Modelu B** (hledte souadnice v New Yorku), nikdy se nepotkte. Proto v celm notebooku pouvme jednu promnnou `embeddings`.\n",
                "\n",
                "---\n",
                "\n",
                "## 3. Jak se \"Testovac slovo\" a \"Vector Store\" propoj?\n",
                "Toto je ten magick moment RAGu (Retrieval-Augmented Generation). Funguje to ve tech krocch:\n",
                "\n",
                "### Krok A: Uloen (Ingestion)  \"Zapichovn vlajeek\"\n",
                "1.  Vezmeme vtu ze smlouvy: *\"Smlouva plat 5 let.\"*\n",
                "2.  Poleme ji do `embeddings` modelu.\n",
                "3.  Model vrt souadnice: `[0.1, 0.5, 0.9 ...]`.\n",
                "4.  Tyto souadnice **ulome do Vector Store** (ChromaDB) a dme k nim lsteek s pvodnm textem.\n",
                "    *   *Efekt: Mme databzi plnou vlajeek zapchanch na map podle vznamu.*\n",
                "\n",
                "### Krok B: Dotaz (Query)  \"Kde jsem j?\"\n",
                "1.  Uivatel (nebo vy v testu) nape dotaz: *\"Jak dlouho to plat?\"* (Vimnte si, e jsme nepouili stejn slova).\n",
                "2.  Tento dotaz poleme do **toho samho `embeddings` modelu**.\n",
                "3.  Model vrt souadnice pro tento dotaz: `[0.11, 0.51, 0.89 ...]`.\n",
                "\n",
                "### Krok C: Hledn (Search)  \"Kdo je mm sousedem?\"\n",
                "1.  Vektorov databze dostane souadnice vaeho dotazu.\n",
                "2.  Rozhldne se kolem tohoto bodu a hled **nejbli zapchnutou vlajeku**.\n",
                "3.  Najde vlajeku *\"Smlouva plat 5 let\"*, protoe jej souadnice jsou matematicky nejbl (le na stejnm \"nmst vznamu\").\n",
                "4.  Vrt vm ten pvodn text."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "d64022db",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Testovac slovo: 'apple'\n",
                        "   - Dlka vektoru: 1536 dimenz (standard pro model ada-002 je 1536)\n",
                        "   - Prvnch 5 sel vektoru: [0.007782285567373037, -0.023080386221408844, -0.007522648200392723, -0.02772652730345726, -0.00455048494040966]...\n",
                        "   - Typ dat: <class 'list'>\n",
                        "\n",
                        "========================================\n",
                        "\n",
                        " VectorStore (ChromaDB):\n",
                        "   - Jmno kolekce: rag_training_v1\n",
                        "   - Poet uloench vektor: 9\n",
                        "\n",
                        " Rychl test hledn slova 'contract':\n",
                        "   - Nalezen dokument: 'Quarter: Q4 2023\n",
                        "Revenue: 950000\n",
                        "Expenses: 750000\n",
                        "Profit: 200000\n",
                        "Notes: Previous year comparison....'\n",
                        "   - Zdroj: {'source': '../data/finance/financial_report.csv', 'row': 3}\n"
                    ]
                }
            ],
            "source": [
                "# --- INSPEKCE EMBEDDINGS A VECTOR STORE ---\n",
                "\n",
                "# 1. Testovac Embedding\n",
                "# Co to je: Vektor, kter reprezentuje vznam slova \"test\".\n",
                "# Pro: Ovme, e model funguje a podvme se, jak vypad \"strojov e\".\n",
                "test_word = \"apple\"\n",
                "try:\n",
                "    vector = embeddings.embed_query(test_word)\n",
                "    print(f\" Testovac slovo: '{test_word}'\")\n",
                "    print(f\"   - Dlka vektoru: {len(vector)} dimenz (standard pro model ada-002 je 1536)\")\n",
                "    print(f\"   - Prvnch 5 sel vektoru: {vector[:5]}...\")\n",
                "    print(f\"   - Typ dat: {type(vector)}\")\n",
                "except Exception as e:\n",
                "    print(f\" Chyba pi vytven embeddingu: {e}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
                "\n",
                "# 2. Vector Store (ChromaDB)\n",
                "# Co to je: Databze, kde jsou uloeny vektory vech naich chunk.\n",
                "# Pro: Abychom v nich mohli rychle hledat podle podobnosti.\n",
                "print(f\" VectorStore (ChromaDB):\")\n",
                "# ChromaDB v LangChainu zapouzduje kolekci\n",
                "try:\n",
                "    if hasattr(vectorstore, \"_collection\"):\n",
                "        print(f\"   - Jmno kolekce: {vectorstore._collection.name}\")\n",
                "        print(f\"   - Poet uloench vektor: {vectorstore._collection.count()}\")\n",
                "\n",
                "    # Zkusme najt nco podobnho slovu \"contract\"\n",
                "    # Toto ov, e vyhledvn funguje end-to-end\n",
                "    results = vectorstore.similarity_search(\"contract\", k=1)\n",
                "    if results:\n",
                "        print(f\"\\n Rychl test hledn slova 'contract':\")\n",
                "        print(f\"   - Nalezen dokument: '{results[0].page_content[:100]}...'\")\n",
                "        print(f\"   - Zdroj: {results[0].metadata}\")\n",
                "    else:\n",
                "        print(\"\\n Hledn vrtilo 0 vsledk (to je divn, pokud mme data).\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\" Chyba pi prci s VectorStore: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Basic Retrieval (Smantick vyhledvn)\n",
                "\n",
                "V pedchozm kroku jsme dokumenty rozsekali, pevedli na sla (vektory) a uloili do **Vektorov databze (Chroma)**. Nyn si ukeme, jak v tchto datech hledat odpovdi.\n",
                "\n",
                "###  Jak to funguje pod kapotou?\n",
                "\n",
                "Kd `docs = vectorstore.similarity_search(question, k=3)` vypad jednodue, ale spout komplexn proces, kter spojuje ve, co jsme dote udlali.\n",
                "\n",
                "Aby databze mohla najt odpov, mus se stt nsledujc:\n",
                "\n",
                "1.  **Transformace otzky (Embeddings):**\n",
                "    *   V dotaz (`question`) je pouze text. Databze ale rozum jen slm.\n",
                "    *   Proto se systm (objekt `vectorstore`) podv na svou konfiguraci **Embeddings** (n \"model/peklada\").\n",
                "    *   Pole v dotaz do modelu (Azure OpenAI) a zsk zpt **vektor otzky** (seznam sel reprezentujc vznam otzky).\n",
                "    *   **Dleit:** Musme pout *pln stejn* model (Embeddings), jak jsme pouili pi ukldn dokument. Jinak by sla nesedla.\n",
                "\n",
                "2.  **Matematick porovnn (Similarity Search):**\n",
                "    *   ChromaDB vezme **vektor otzky** a porovn ho se vemi miliardami **vektor dokument**, kter m uloen.\n",
                "    *   Hled tzv. *nejbli sousedy*  tedy dokumenty, jejich vznamov vektor je matematicky nejble vektoru otzky.\n",
                "\n",
                "3.  **Vbr kontextu (Retrieval):**\n",
                "    *   Databze vrt `k` (nap. 3) nejlepch ryvk textu. Tyto ryvky pak pedhodme LLM jako podklad pro odpov.\n",
                "\n",
                "---\n",
                "\n",
                ">  **Architektura v reln aplikaci vs. Notebook**\n",
                ">\n",
                "> V tomto vukovm notebooku dlme ve najednou: vytvome databzi a hned se j zeptme. V reln produkn aplikaci (\"chatbotovi\") jsou tyto procesy oddlen:\n",
                ">\n",
                "> 1.  **Ingestion Pipeline (Non proces):** Skript, kter jednou za as vezme dokumenty, vytvo/aktualizuje databzi a **ulo ji na disk**.\n",
                "> 2.  **Aplikace (Chatbot):** B neustle. Pi startu nic nevytv, pouze se **pipoj** k ji existujc databzi na disku (tzv. nate `persisted_directory` a pouije stejn `embeddings` model) a rovnou hled."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\jan.petr\\AppData\\Local\\Temp\\ipykernel_57296\\3287707502.py:23: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
                        "  vectorstore = Chroma(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " spn pipojeno k databzi. Obsahuje 9 dokument.\n",
                        "\n",
                        "[Result 1] Source: ../data/legal/sla_contract.txt\n",
                        "SERVICE LEVEL AGREEMENT (SLA) for NebulaDB Enterprise\n",
                        "\n",
                        "1. DEFINITIONS\n",
                        "\"Uptime\" refers to the availability of the Service during a billing month.\n",
                        "\"Downtime\" refers to a period of time exceeding 5 minutes where the Error Rate is greater than 5%.\n",
                        "\n",
                        "2. SERVICE COMMITMENT\n",
                        "NebulaDB commits to a Monthly Uptime Percentage of at least 99.99% (\"Service Commitment\").\n",
                        "\n",
                        "[Result 2] Source: ../data/legal/sla_contract.txt\n",
                        "4. EXCLUSIONS\n",
                        "The Service Commitment does not apply to any unavailability, suspension, or termination of NebulaDB performance issues: (i) caused by factors outside of our reasonable control, including any force majeure event or Internet access or related problems beyond the demarcation point of NebulaDB.\n",
                        "\n",
                        "5. CLAIMS\n",
                        "To receive a Service Credit, you must submit a claim by opening a case in the NebulaDB Support Center within 30 days of the incident.\n",
                        "\n",
                        "[Result 3] Source: ../data/legal/sla_contract.txt\n",
                        "3. SERVICE CREDITS\n",
                        "If we do not meet the Service Commitment, you will be eligible to receive a Service Credit as follows:\n",
                        "- < 99.99% but >= 99.0%: 10% Credit\n",
                        "- < 99.0% but >= 95.0%: 25% Credit\n",
                        "- < 95.0%: 100% Credit\n"
                    ]
                }
            ],
            "source": [
                "question = \"What is the SLA for downtimes?\"\n",
                "\n",
                "\n",
                "\n",
                "# --- SIMULACE: Naten ji existujc databze (Query Only) ---\n",
                "from langchain_openai import AzureOpenAIEmbeddings\n",
                "from langchain_community.vectorstores import Chroma\n",
                "import os\n",
                "# 1. Musme inicializovat Embeddings\n",
                "# Databze potebuje vdt, jakm \"jazykem\" (modelem) m pevdt v dotaz na sla.\n",
                "# Mus to bt STEJN model, jakm jste data uloili!\n",
                "embeddings = AzureOpenAIEmbeddings(\n",
                "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
                "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
                "    azure_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\"),\n",
                "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\"),\n",
                ")\n",
                "# 2. Naten existujcho VectorStore z disku\n",
                "# Nepouvme .from_documents(), protoe nechceme nic vkldat.\n",
                "# Jen ekneme: \"Tady je sloka s daty, pouij ji.\"\n",
                "persist_directory = \"../chroma_db\"  # Cesta ke sloce z pedchozch krok\n",
                "if os.path.exists(persist_directory):\n",
                "    vectorstore = Chroma(\n",
                "        persist_directory=persist_directory,\n",
                "        embedding_function=embeddings,\n",
                "        collection_name=\"rag_training_v1\"\n",
                "    )\n",
                "    print(f\" spn pipojeno k databzi. Obsahuje {vectorstore._collection.count()} dokument.\")\n",
                "else:\n",
                "    print(f\" Chyba: Sloka {persist_directory} neexistuje. Muste nejdve spustit Ingestion st (vytvoen databze).\")\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "docs = vectorstore.similarity_search(question, k=3)\n",
                "\n",
                "for i, doc in enumerate(docs):\n",
                "    print(f\"\\n[Result {i+1}] Source: {doc.metadata.get('source')}\")\n",
                "    print(doc.page_content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Generation (The 'G' in RAG)\n",
                "\n",
                "Finally, we pass the retrieved chunks to the LLM to write the answer."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "63670b02",
            "metadata": {},
            "source": [
                "#  Anatomie RAG etzce: Co se dje pod kapotou?\n",
                "Tento dokument vysvtluje logiku RAG (Retrieval-Augmented Generation) pipeline postaven pomoc modernho **LCEL (LangChain Expression Language)**. Jednotliv kroky na sebe navazuj jako na vrobn lince.\n",
                "## 1. Definice LLM (Mozek)\n",
                "```python\n",
                "llm = AzureChatOpenAI(\n",
                "    azure_deployment=\"gpt-4o\",  # V deployment v Azure\n",
                "    openai_api_version=\"2023-05-15\",\n",
                "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
                "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
                "    temperature=0\n",
                ")\n",
                "```\n",
                "*   **Co se dje:** Inicializujeme spojen s jazykovm modelem (GPT-4o) bcm v cloudu Azure.\n",
                "*   **Pro to dlme:** Potebujeme \"mozek\", kter na konci procesu vygeneruje srozumitelnou odpov na zklad nalezench dat.\n",
                "*   **Klov parametr:** `temperature=0`. Pro RAG systmy chceme nulu, aby model \"nehalucinoval\" a drel se striktn nalezench fakt.\n",
                "## 2. Retriever (Vyhledva)\n",
                "```python\n",
                "retriever = vectorstore.as_retriever()\n",
                "```\n",
                "\n",
                "*   **Co se dje:** Pevdme statickou databzi (VectorStore) na aktivn vyhledvac komponentu.\n",
                "*   **Pro to dlme:** VectorStore um jen ukldat. My potebujeme funkci, do kter hodme otzku (string) a ona nm vrt seznam relevantnch dokument.\n",
                "## 3. Prompt Template (ablona instrukc)\n",
                "```python\n",
                "template = \"\"\"Answer the question based only on the following context: {context}\n",
                "\n",
                "Question: {question} \"\"\"\n",
                "\n",
                "prompt = ChatPromptTemplate.from_template(template)\n",
                "```\n",
                "\n",
                "*   **Co se dje:** Pipravujeme \"formu\", do kter se budou vkldat data.\n",
                "*   **Logika:** ablona m dv msta (promnn), kter je teba vyplnit:\n",
                "    1.  `{context}`: Sem se vlo texty nalezen v dokumentech (vae znalostn bze).\n",
                "    2.  `{question}`: Sem se vlo aktuln dotaz uivatele.\n",
                "\n",
                "## 4. Helper Funkce (Formtova dokument)\n",
                "```python\n",
                "def format_docs(docs): \n",
                "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
                "```\n",
                "*   **Co se dje:** Tato funkce bere sloit objekty `Document` (kter vrac retriever) a vytahuje z nich ist text.\n",
                "*   **Pro to dlme:** Retriever vrac metadata, zdrojov cesty atd. LLM ale zajm jen obsah. Funkce vezme obsah vech nalezench dokument a spoj je do jednoho dlouhho textu oddlenho mezerami, aby se veel do promnn `{context}`.\n",
                "\n",
                "## 5. Sestaven etzce (The Pipeline)\n",
                "Toto je nejdleitj st. Definujeme tok dat pomoc opertoru `|` (pipe), kter posl vstup z jedn funkce jako vstup do dal.\n",
                "```python\n",
                "rag_chain = ( {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
                " | prompt\n",
                " | llm\n",
                " | StrOutputParser() )\n",
                "\n",
                "\n",
                " # Pseudo-kd toho, co se dje uvnit jen pro ukzku:\n",
                "rag_chain = RunnableSequence(\n",
                "    first=RunnableParallel(  # Ten slovnk na zatku\n",
                "        context=(retriever | format_docs),\n",
                "        question=RunnablePassthrough()\n",
                "    ),\n",
                "    middle=[\n",
                "        prompt,  # ChatPromptTemplate\n",
                "        llm,     # AzureChatOpenAI\n",
                "        StrOutputParser()\n",
                "    ]\n",
                ")\n",
                "```\n",
                "### Krok A: Paraleln pprava dat (Slovnk na zatku)\n",
                "`{\"context\": ..., \"question\": ...}`\n",
                "Tento blok b jako prvn a pipravuje data pro prompt. Dl dv vci narz:\n",
                "1.  **Zskn kontextu:** `retriever | format_docs`\n",
                "    *   Vezme vstupn otzku -> pole ji do `retriever` (najde dokumenty) -> vsledek pole do `format_docs` (pevede na text) -> ulo jako `context`.\n",
                "2.  **Pedn otzky:** `\"question\": RunnablePassthrough()`\n",
                "    *   `RunnablePassthrough()` je \"prtokov ohva\". Vezme vstupn otzku a beze zmny ji pole dl pod klem `question`.\n",
                "### Krok B: Vytvoen zadn\n",
                "`| prompt`\n",
                "*   Vezme data z kroku A (naplnn `context` i `question`) a vlo je do ablony z bodu 3. Vsledkem je finln text zadn pro model.\n",
                "### Krok C: Generovn odpovdi\n",
                "`| llm`\n",
                "*   Hotov zadn se pole do GPT-4o. Model vygeneruje odpov (objekt typu `AIMessage`).\n",
                "### D. ist vstup\n",
                "`| StrOutputParser()`\n",
                "*   Model vrac sloit objekt. Tento parser z nj vythne ist etzec (string) s odpovd, kterou vid uivatel.\n",
                "## 6. Sputn (Execution)\n",
                "response = rag_chain.invoke(question)\n",
                "\n",
                "*   **Co se dje:** Metoda `.invoke()` je spoutc tlatko.\n",
                "*   Funkce vezme promnnou `question` (v dotaz) a hod ji na zatek etzce (do bodu 5).\n",
                "*   Cel proces probhne automaticky a na konci vypadne textov odpov."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "88fe5b77",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Otzka: What is the SLA for downtimes?\n",
                        "------------------------------\n",
                        "Odpov: The SLA for downtimes in the NebulaDB Enterprise Service Level Agreement specifies that \"Downtime\" refers to a period of time exceeding 5 minutes where the Error Rate is greater than 5%.\n"
                    ]
                }
            ],
            "source": [
                "# Modern a spolehliv alternativa k RetrievalQA\n",
                "from langchain_openai import AzureChatOpenAI\n",
                "import os\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from langchain_core.runnables import RunnablePassthrough\n",
                "\n",
                "# 1. Definice LLM (Pouvme Azure variantu)\n",
                "# Nateme promnn prosted, kter jste definoval v pedchozch bukch nebo .env souboru\n",
                "llm = AzureChatOpenAI(\n",
                "    azure_deployment=\"gpt-4o\",  # Pedpokldme, e nzev deploymentu v Azure je \"gpt-4o\"\n",
                "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2023-05-15\"),\n",
                "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
                "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
                "    temperature=0\n",
                ")\n",
                "\n",
                "# 2. Retriever (Vyhledva)\n",
                "retriever = vectorstore.as_retriever()\n",
                "\n",
                "# 3. Prompt (Instrukce pro model)\n",
                "template = \"\"\"Answer the question based only on the following context:\n",
                "{context}\n",
                "\n",
                "Question: {question}\n",
                "\"\"\"\n",
                "prompt = ChatPromptTemplate.from_template(template)\n",
                "\n",
                "# 4. Pomocn funkce pro zformtovn dokument do textu\n",
                "def format_docs(docs):\n",
                "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
                "\n",
                "# 5. Sestaven RAG etzce (Chain)\n",
                "rag_chain = (\n",
                "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
                "    | prompt\n",
                "    | llm\n",
                "    | StrOutputParser()\n",
                ")\n",
                "\n",
                "# 6. Sputn\n",
                "# .invoke() spust cel proces: najde dokumenty -> vlo do promptu -> odele na GPT-4\n",
                "print(f\"Otzka: {question}\")\n",
                "print(\"-\" * 30)\n",
                "response = rag_chain.invoke(question)\n",
                "print(\"Odpov:\", response)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "47e8277b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
                    ]
                }
            ],
            "source": [
                "print(type(rag_chain))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
